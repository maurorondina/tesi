<?xml version="1.0" encoding="utf-8"?>
<paper id="2535" url="http://www.aaai.org/Papers/AAAI/2000/AAAI00-081.pdf">
 <title id="2535.0" name="Bayesian Fault Detection and Diagnosis in Dynamic Systems"/>
 <subsection id="2535.0.1">
  Uri Lerner Computer Science Dept.
 </subsection>
 <subsection id="2535.0.2">
  Stanford University uri@cs.stanford.edu Ronald Parr Computer Science Dept.
 </subsection>
 <subsection id="2535.0.3">
  Stanford University parr@cs.stanford.edu Daphne Koller Computer Science Dept.
 </subsection>
 <subsection id="2535.0.4">
  Stanford University koller@cs.stanford.edu Gautam Biswas Department of EECS Vanderbilt University biswas@vuse.vanderbilt.edu
 </subsection>
 <paragraph id="2535.1" name="Abstract">
  <subsection id="2535.1.1">
   This paper addresses the problem of tracking and diagnosing complex systems with mixtures of discrete and continuous variables. This problem is a difficult one, particularly when the system dynamics are nondeterministic, not all aspects of the system are directly observed, and the sensors are subject to noise. In this paper, we propose a new approach to this task, based on the framework of hybrid dynamic Bayesian networks (DBN). These models contain both continuous variables representing the state of the system and discrete variables representing discrete changes such as failures; they can model a variety of faults, including burst faults, measurement errors, and gradual drifts. We present a novel algorithm for tracking in hybrid DBNs, that deals with the challengesposed by this difficult problem. We demonstrate how the resulting algorithm can be used to detect faults in a complex system.
  </subsection>
 </paragraph>
 <paragraph id="2535.2" name="Introduction">
  <subsection id="2535.2.1">
   The complexity and sophistication of the current generation of industrial processes, and the growing need for autonomous agents that control physical systems, motivate the need for robust online monitoring and diagnosis of complex hybrid systems (e.g., (Isermann 1997) and (McIlraith et al.
  </subsection>
  <subsection id="2535.2.2">
   2000)). We want to monitor the state of the system, reliably detect abnormal behavior, and diagnose the failure. Several approaches have been used for dealing with this problem, but each has its limitations. The traditional modelbased schemes for diagnosis and control suffer from computational intractability and numerical convergence problems. The qualitative reasoning mechanisms that dominate this work in the AI community mitigate some of these problems; however, the lack of precision in the representation, and the ambiguities introduced by the reasoning framework can lead them to perform poorly when applied to complex system with continuous dynamics (Hamscher, Console, &amp; de Kleer (eds.) 1992).
  </subsection>
  <subsection id="2535.2.3">
   In this paper, we propose a different approach to this problem, where we model a complex hybrid system as a dynamic Bayesian network (DBN). This model implicitly defines a probabilitydistributionover projected trajectories of the system state over time. In this sense, it is similar to the very successful Kalman filter (Kalman 1960). For systems with linear dynamics and Gaussian noise, the Kalman filter provides an excellent means for tracking system state. Unfortunately, real-life systems are rife with nonlinearities, many of Copyright c 2000, American Association for Artificial Intelligence (www.aaai.org). All rights reserved.
  </subsection>
  <subsection id="2535.2.4">
   which are expressed as discrete failure modes that can produce discontinuousjumps in system behavior. Hybrid DBNs accommodate a much greater range of problems, including nonlinear dynamics and discrete failure modes that influence system evolution. They can directly represent the noise associated with the system evolution and measurements, as well as the probabilities of faults and their effects.
  </subsection>
  <subsection id="2535.2.5">
   We first show that many interesting aspects of diagnostic models can be represented in the DBN framework. In particular, we show that they allow a natural encoding of the representation of higher-order system dynamics used in the temporal causal graph (TCG) framework of Mosterman and Biswas (1997). In fact, a TCG can be used to provide the skeleton for an appropriate DBN model. We also show that many interesting types of failures can be modeled naturally in the DBN, including burst faults, parameter drift, and measurement errors.
  </subsection>
  <subsection id="2535.2.6">
   There are several advantages to the use of general probabilistic models, such as DBNs, for fault detection and diagnosis. A DBN is complete model of the system. Using this model, the state of the system, including its failure modes, is tracked by maintaining a probability distributionover possible system states given all of the measurements so far. This belief state distributionis an exact representation of our best possible beliefs given all of the available evidence. It includes within it the likelihood of different types of failures, as well as a distributionover the relevant system parameters.
  </subsection>
  <subsection id="2535.2.7">
   In principle, many of the issues that have challenged traditional approaches to diagnosis — ranking possible failures, handling of multiple simultaneous failures, and robustness to parameter drift — can be addressed within a probabilistic tracking framework.
  </subsection>
  <subsection id="2535.2.8">
   Of course, the inference task that is required for maintaining this belief state is a difficult one. Unlike the case of a simple Kalman filter, tracking such systems is generally intractable since the number of modes of these systems grows exponentially over time. We present a novel algorithm that tames this intractability using a combination of several different techniques. We show that this algorithm succeeds in tracking a very difficult scenario on a fairly large system (one involving five tanks). We believe that our approach will scale well to substantially more complex systems.
  </subsection>
 </paragraph>
 <paragraph id="2535.3" name="The framework">
  <subsection id="2535.3.1">
   Diagnosis of hybrid systems To ground our discussion, we will focus on the diagnosis task for a class of problems typical of chemical manufacFrom: AAAI-00 Proceedings. Copyright © 2000, AAAI (www.aaai.org). All rights reserved.
  </subsection>
  <subsection id="2535.3.2">
   (a) Tank 2 Tank 1 P2 P1 F1o F2o F12 R12 R1o R2o In flow (b) F12’ = = P2’’ -P12 1 -1 = -1 = = -1 -1 1 = 1 P1 P1’ P2’ F2o F2o P2 P12 F12 F4 F2T F1 F1T 1 R12 1 R1o 1 Rb2 dt 1 C1 dt 1 C2 Figure 1: The two-tank system. F indicates flow; P indicates pressure; R indicates Resistance.
  </subsection>
  <subsection id="2535.3.3">
   turing processes, which involve the transport of materials (mostly fluids) into and between tanks. Such domains are well-represented using bond graph formalism (Rosenberg &amp; Karnopp 1983), where the dynamic behavior of the system is defined by fluid pressures and fluid flow-rates. Consider, for example, a simple two-tank model, shown in Figure 1(a).
  </subsection>
  <subsection id="2535.3.4">
   The model represents a system with two tanks that can hold fluids, an inlet pipe into tank 1, two outlet pipes, and a connecting pipe between the tanks. The storage tanks are capacitive elements and the connecting pipes are resistive elements. This system is a second order system with natural feedback mechanisms.
  </subsection>
  <subsection id="2535.3.5">
   The temporal causal graph (TCG) framework of (Mosterman &amp; Biswas 1997) is a topological representation that captures local dynamic relations between variables, and provides a more explicit representation of the relation between system parameters and the behavior variables. The TCG for the two-tank example is shown in Figure 1(b). Here, the variables are the pressure and flow-rate variables associated with the tanks and the pipes in the system. Causal edges in a TCG are labeled with component parameter values and temporal information derived from the characteristics of the related components. Resistive and junction components introduce algebraic relations among the system variables, and therefore, define instantaneous temporal relations such as a direct or inverse proportionality between the variables (denoted by 1). On the other hand, energy storage elements, like capacitive and inductive elements, introduce integral relations between system variables (labeled with a dt). For example, capacitive relations from the flow-rate variable to the pressure variable are labeled with a 1 C dt; this implies a temporal relation, i.e., the flow-rate affects the derivative of the corresponding pressure variable.
  </subsection>
  <subsection id="2535.3.6">
   Many systems have the property that they behave nearly deterministically in the absence of a fault. The deterministic trajectory of the system is often called its nominal trajectory.
  </subsection>
  <subsection id="2535.3.7">
   In such cases, faults are sometimes defined implicitly as any abrupt change in a parameter that causes a deviation from the nominal trajectory. Since the temporal causal graph defines a set of qualitative constraints on the system it can be used to predict the effects of sudden discontinuous changes in parameters, e.g., burst faults. By contrast, TCGs generally are not used identify parameter drift failures, which are the result of gradual changes in system parameters that accumulate over time.
  </subsection>
  <subsection id="2535.3.8">
   Dynamic Bayesian Networks A dynamic Bayesian network (DBN) is a temporal stochastic model for a dynamic system. It assumes that the system state can be represented by a set of variables, denoted Z.
  </subsection>
  <subsection id="2535.3.9">
   Each of these variables Zi can be real-valued or discrete.
  </subsection>
  <subsection id="2535.3.10">
   We use Dt  Zt to denote the discrete variables in the state. We partition the continuous variables into two subsets: the subset Y  Z are variables that are measurements, i.e., their value is known to us; the remaining subset X are unobserved.
  </subsection>
  <subsection id="2535.3.11">
   The system is modeled as evolving in discrete time steps.
  </subsection>
  <subsection id="2535.3.12">
   Thus, each system variable Z has an instantiation Zt for each time slice t. A DBN is a compact graphical representation for the two-time-slice conditional probability distribution P(Zt+1 j Zt ). It encompasses both the transition model and the observation model. More formally, a DBN is a directed acyclic graph, whose nodes are random variables in two consecutive time slices: Zt and Zt+1. The edges in the graph represent the direct dependence of a time t + 1 variable Zt+1 i on its immediate causes Par(Zt+1 i ).
  </subsection>
  <subsection id="2535.3.13">
   Each such node is annotated with a conditional probability distribution (CPD), that defines the local probability model P(Zt+1 i j Par(Zt+1 i )). The DBN model is a compact representation for the two-time-slice distribution via the chain rule: P(Zt+1 j Zt ) = Q i P(Zt+1 i j Par(Zt+1 i )). We note that the transition probabilities for any variable are determined completely by the value of the variables in the current and previous time step. This Markov assumption requires us to model explicitly any variables, such as failures, that induce long-term correlations on the system state. We return to this issue below.
  </subsection>
  <subsection id="2535.3.14">
   For the diagnostic tasks that we focus on, we can restrict attention to a very natural subclass of hybrid DBNs — the conditional linear Gaussian (CLG) models. Here, we we require that discrete nodes cannot have continuous parents.
  </subsection>
  <subsection id="2535.3.15">
   We also require that the CPD for a continuous variable be a conditional linear Gaussian. Roughly speaking, in a linear Gaussian dependence, the node is a linear function of its parents with Gaussian noise, where the parameters of the linear dependence can depend on the discrete parents. More precisely, if a node X has continuous parents Y1;:::;Yk and discrete parents U, we parameterize its CPD using parameters au;0;:::;au;k and 2 u for every instantiation u to the discrete parents U. Then P(X j y;u) is a Gaussian distribution with a mean au;0 +Pk i=1 au;iyi and variance 2 u.
  </subsection>
  <subsection id="2535.3.16">
   It is important to note that, without discrete variables in the network, this type of DBN defines standard linear Gaussian dynamics. Hence, in this case, the DBN is simply a graphical representation of the standard dynamics used in a Kalman filter, albeit one that makes certain independence  R12 R2o R2o P2 12 1 1o P1 D2o D R R 1o D1o D 12 P2 D12 R1o E1o E12 E2o P 2o M D 1o 12 2o M M F 1o F 12 F 1o F 12 F 2o F 2o Figure 2: The two-tank DBN.
  </subsection>
  <subsection id="2535.3.17">
   assumptions explicit. In the presence of discrete parents, the model represents a mixture of linear models, with the mixtures determined by the discrete variables.
  </subsection>
  <subsection id="2535.3.18">
   DBNs for diagnosis Our goal is to represent a diagnostic system, of the type described above, as a DBN. It turns out that we can use a TCG for a system as a “blueprint”for the skeleton of the DBN. We can think of a TCG as a schema for a system of equations describing the continuous system dynamics. We distinguish two types of arcs in a TCG: temporal arcs are annotated with a dt, whereas non-temporal arcs are not. For any variable X with no incoming temporal arcs, the TCG expresses an instantaneous constraint on X as a function of its predecessors. For a variable X with at least one incoming temporal arc, the TCG expresses a temporal constraint.
  </subsection>
  <subsection id="2535.3.19">
   We generate a DBN structure from a TCG as follows: For each node Xi in the temporal causal graph, we create Xt i and Xt+1 i to denote the state of the variable at two consecutive time points. (In practice, we will merge nodes that are connected by equality constraints in the TCG.) Let Xj be a node in the TCG which is a direct predecessor of Xi. If the arc from Xj to Xi is non-temporal, we add an arc from Xt j to Xt i and an arc fromXt+1 j to Xt+1 i . If the arc is temporal, we add an arc only from Xt j to Xt+1 i . This process suffices to generate the structure for a DBN that models the nominal behavior the system.
  </subsection>
  <subsection id="2535.3.20">
   We then want to add variables that model our observations and represent the failure modes of the system. Our framework accommodates for a wide variety of failure modes. In our presentation, we focus on three important types: burst failures, measurement failures and parameter drift failures.
  </subsection>
  <subsection id="2535.3.21">
   To accommodate these, we need to make two important additions to the TCG induced DBN. Since any parameter that can change must be modeled in the DBN, we add nodes to model the resistance variables. In our implementation, these were conductances and not resistances, since we preferred to use a multiplicative model. We also need to add nodes corresponding to presence of burst failures and the presence of measurement failures.
  </subsection>
  <subsection id="2535.3.22">
   Figure 2 shows a DBN created by this process. The nodes F1t and F2t simply add incoming flows and this function has been subsumed by the CPDs for P1 and P2. The nodes labeled with M correspond to our measurements of the flow parameters in the system and the discrete nodes labeled with E indicate the presence of measurement failures. For example, we define the CPD of M12 to be a normal distribution around F12 with small variance when E12 is false, but with a much larger variance when the E12 is true. The R variables model the conductances in the system. These have discrete parents, D, that indicate the presence of faults. Unlike the measurement fault variables, these fault variables have parents in the previous DBN time slice. This is necessary to model persistent events such as drifts. Each conductance fault variable takes on four values: stable, fault, buildup and leak. When the system is stable, the CPD of the corresponding R has low noise. When a fault occurs, there is a sharp increase in the variance of the corresponding R. The two drift faults produce a small drift, defined as a percentage of the parameter’s previous value. We need the temporal connection between the D nodes to reflect the fact that drifts persist; once a buildup starts in a pipe it tends to continue.
  </subsection>
 </paragraph>
 <paragraph id="2535.4" name="Inference">
  <subsection id="2535.4.1">
   In this section, we propose an inference procedure for fault diagnosis and detection in models represented as DBNs. As we have mentioned, we can view DBNs as a structured representation and extension of traditional Kalman filters.
  </subsection>
  <subsection id="2535.4.2">
   We therefore build our algorithm starting from the classical Kalman filter algorithm. Typical extensions to this algorithm maintain multiple candidate hypotheses about the state of the system. At each time step they update a set of candidate hypotheses and prune out unlikelyones based upon evidence. If the correct hypothesis remains in the candidate set, these algorithms will track the state of the system correctly.
  </subsection>
  <subsection id="2535.4.3">
   The problem with this type of approach is that it is very difficult to determine which hypotheses to keep for complex systems: there are too many possible new hypotheses at each time, and the information needed to prune away bad hypotheses often is not manifested until several time steps after the hypotheses are generated. We present a novel approach that collapses similar hypotheses into a single hypothesis, then present a novel approximate smoothing algorithm that we use to improve our ability to effectively reduce the number of hypotheses. This approach allows us to deal with complex failure modes and sequences involving many failures. But it does not scale to complex systems that involve many possible failures in different components. We address this problem by combining our techniques with a decomposition method based on the algorithm of Boyen and Koller (1998) that allows the tracking of very large systems.
  </subsection>
  <subsection id="2535.4.4">
   Tracking and smoothing Our dynamic Bayesian network represents the complete state of the system at each time step; it includes variables for the various aspects of the continuous state of the system such as pressures or conductances, as well as discrete variables representing possible failures. This complete model allows us to reduce the problems of fault detection and diagnosis to the task of tracking (or filtering) a stochastic dynamic system. The tracking problem is defined as follows.
  </subsection>
  <subsection id="2535.4.5">
   As the system evolves, we get observations y1;y2;:::. At time t, our most informed evaluation of the state of the system is our posterior distribution P(Zt j y1;:::;yt ) about the current system state given all of our observations so far.
  </subsection>
  <subsection id="2535.4.6">
   We call this posterior distribution our time t belief state, and denote it using t . The probability of a discrete fault variable in this belief state takes into consideration all of the evidence up to the present to determine the probability that this fault has occurred.
  </subsection>
  <subsection id="2535.4.7">
   In principle, tracking is a very easy task, which can be accomplished by the following propagation formula: t+1(zt+1)= P(yt+1 j zt+1) Z t (zt )P(zt+1 j zt )dzt where is a normalizing constant. This process is known as a forward pass.
  </subsection>
  <subsection id="2535.4.8">
   Forward tracking gives the best estimate of the likelihood of a fault given the evidence so far. It cannot, however, deal with cases where a fault is momentary, but whose direct effects are unobservable so that its effects become visible to our sensor only later on. The reason is that, at the time that the evidence indicates the presence of a previous failure, there is no longer a variable in the belief state that represents the occurrence of that failure. There is a variable denoting this event at an earlier time slice, but the forward pass only maintains beliefs about variables in the current time step.
  </subsection>
  <subsection id="2535.4.9">
   To explicitly discover faults of this type, we need to also reason backwards in time, from our current evidence to the time slice where the fault took place. This process is known as smoothing. Given evidence y1;:::;yt+` , we compute P(Zt j y1;:::;yt ;:::;yt+` ). The smoothing process involves a backward pass where evidence from t +` is transmitted backwards over the intervening time slices, updating each of them. We omit details for lack of space.
  </subsection>
  <subsection id="2535.4.10">
   One case of enormous practical importance is the case of linear systems. These systems are fully continuous, with linear Gaussian CPDs. In this case, Zt+1 is a linear function of Zt and Yt+1 is a linear function of Zt+1, both with some added Gaussian noise. In this case, the belief state can be represented exactly as a multivariate Gaussian distribution over Zt . This is the basis for an elegant tracking algorithm called the Kalman filter (Kalman 1960) which maintains this belief state in closed form as the system evolves.
  </subsection>
  <subsection id="2535.4.11">
   Nonlinearities Unfortunately, often we cannot apply the Kalman filter directly to real-life problems, since many real-life systems are not linear systems. The continuous relationships between variables are often nonlinear and the failure modes of the system are often discrete, introducing discontinuous changes in system parameters. When the system is nonlinear, the belief state is no longer a multivariate Gaussian, and rarely has a compact closed form representation.
  </subsection>
  <subsection id="2535.4.12">
   Consider our simple two-tank model. Here, we have a product of two random variables: the flow F is the product of the pressure P and the conductance 1 R . A standard solution to this type of problem is to approximate the nonlinear dynamics with linear dynamics, and then use a standard linear Gaussian model. Thus, we try to get the best approximation for the first and second moments, and ignore the rest.
  </subsection>
  <subsection id="2535.4.13">
   The classical method of linearizing is called the Extended Kalman Filter (Bar-Shalom  Fortmann 1988); it approximates the nonlinear function using its second order Taylor series expansion. In our case, the nonlinear function is a product, which is fairly simple, thus we can compute its first and second order moments in closed form.
  </subsection>
  <subsection id="2535.4.14">
   A far more problematic type of nonlinearity is caused by discrete state changes that influence the continuous system dynamics. For example, a fault might drastically change the conditional mean or variance of a continuous variable such as the conductance. This type of situation is represented in our model via the dependence of the continuous variables X on the discrete fault variables D.
  </subsection>
  <subsection id="2535.4.15">
   This type of model creates substantial difficulties for a tracking algorithm. To understand the difficulties, let d1;:::;dt be some particular instantiation of the discrete variables at time 1;:::;t. Given this instantiation, the dynamics of the continuous variables are, once again, linear Gaussian. Hence, the time t belief state, conditioned on d1;:::;dt , is a multivariate Gaussian over Xt . The difficulty is that we have one such Gaussian for every single instantiation d1;:::;dt . Thus, in order to do exact tracking, we need to maintain a separate hypothesis for every combination of the discrete variables at all times. The number of such hypotheses grows exponentially with the length of the sequence, which is clearly unacceptable.
  </subsection>
  <subsection id="2535.4.16">
   A classical tracking algorithm which deals with this problem is described in (Bar-Shalom  Fortmann 1988). The main idea is to maintain our belief state as a smaller set of hypotheses, each of which corresponds to a single multivariate Gaussian. The algorithm, applied to our setting, is as follows. It is convenient to introduce the random variable Ht , each of whose values corresponds to one hypothesis. The distribution of Ht corresponds to the likelihood of the hypothesis. When the algorithm does the forward pass, it considers all the combinations of values of Ht and Dt+1. The result is a mixture with K  jDj components.
  </subsection>
  <subsection id="2535.4.17">
   Each of these new hypotheses is conditioned on the new measurements Yt+1, and using Bayesian conditioning we adjust both the mixture weights and the parameters of the multivariate Gaussians. The algorithm them prunes the hypotheses that have low probability, and selects only the most likely ones to be part of the time t +1 belief state.
  </subsection>
  <subsection id="2535.4.18">
   I our setting, we also wish to maintain values for the persistent discrete state variables, since the state of the system at time t+1depends on these values at time t. We therefore represent the belief state using a simple graphical model of the form Dt Ht ! Xt . Formally, we represent our time  t belief state t as a mixture t (ht ) of K hypotheses, each of which is associated with a single multivariate Gaussian t (Xt j ht )and a discrete distribution t (Dt j ht ) The deficiency of this algorithm is that it selects some hypotheses exactly, while entirely ignoring others. In many cases, the hypotheses that are maintained all correspond to scenarios that are all close to nominal behavior, and are therefore qualitatively quite similar. By contrast, the pruned hypotheses often correspond to a priori unlikely faults, that can lead to very different behaviors. We therefore propose a new approach where similar hypotheses are collapsed.
  </subsection>
  <subsection id="2535.4.19">
   Like the pruning algorithm, we start by performing the forward propagationstep, defining a set of possible hypotheses (Ht ;Dt+1); let ~ Ht+1 be random variable whose values correspond to this larger set of K  jDj hypotheses. Next, the measurements are introduced, and the result is a mixture distribution t+1 over Ht ;Dt+1 and Xt+1. Our task is to generate the t +1hypotheses from this mixture.
  </subsection>
  <subsection id="2535.4.20">
   We define a new set of mixture components Ht+1, each of which aggregates several of the values of ~ Ht+1. The algorithm thereby defines a collapsing matrix that is essentially a deterministic CPD P(Ht+1 j Ht ;Dt+1). This collapsing matrix is used to define the belief state t+1, as a weighted average of the mixture components: t+1(Ht+1) = X ~ Ht+1 P(Ht+1 j ~ Ht+1)t+1( ~ Ht+1) t+1(Dt+1 j Ht+1) = X ~ Ht+1 P( ~ Ht+1 j Ht+1)t+1(Dt+1 j ~ Ht+1) Finally, we define t+1(Xt+1 j Ht ;Dt+1) to be the closest Gaussian approximation(i.e., the Gaussian that has the same mean and covariances as the mixture) to P~ Ht+1 P(~ Ht+1 j Ht+1)P(Xt+1 j ~ Ht+1).
  </subsection>
  <subsection id="2535.4.21">
   The main remaining question is the choice of which hypotheses to collapse. We use a greedy approach, that takes into consideration both the likelihood of the different hypotheses and their similarity to each other. We sort the different hypotheses by their likelihood.1 Then, starting from the most likely hypothesis, we find the closest hypothesis to it, and merge the two. Note that the merged hypothesis will have higher probability, so will remain at the top of the list. When there are no hypotheses that are “close enough”, we move to the next most likely hypothesis in our list. When we have filled our quota of hypotheses, we collapse all the remaining hypotheses into one, regardless of how close they are. As our distance measure, we use the sum of the two relative entropies (KL-distances) (Cover  Thomas 1991) between the Gaussians associated with the hypotheses. We note that we deliberately do not use the weights in determining the distance between hypotheses; otherwise, we wouldinvariably collapse unlikelyhypotheses into likely ones, even if they are qualitatively very different.
  </subsection>
  <subsection id="2535.4.22">
   1 To reduce CPU time in our implementation, we first removed all hypotheseswith extremely low probability (10,8 ), and then use the merging approach to collapse the rest.
  </subsection>
  <subsection id="2535.4.23">
   Smoothing Both hypothesis collapsing and pruning are myopic methods; they only use evidence observed up to time t. As discussed above, the effects of some failures have a delay, so a failure at time t may not manifest itself in evidence up to time t. Since a priori failure probabilities are typically quite low, failures could have very weak support in our belief state. Thus, by the time the data necessary to diagnose the failure are available, the failure track may be lost. The obvious solution to the problem is to pick the likely hypotheses based not only on past and present evidence but also on future evidence; i.e., we want to use weights obtained after some amount of smoothing. However, smoothing requires that we first propagate a belief state forward in time, and this is the very problem we are trying to solve. We break this cycle by using a slightly different method of collapsing hypotheses. Instead of sorting the hypotheses by likelihoods we always collapse the two most similar Gaussians until our mixture is small enough. This may lead to a more aggressive collapsing since we do not have a bound on the maximal KL-distance between two Gaussians that we collapse. We can afford to be more aggressive here since we will not use the results of smoothing to update our continuous variables, but only to guide our hypothesis reduction method.
  </subsection>
  <subsection id="2535.4.24">
   It remains to show how we do the backward propagation process required for smoothing. The primary difficulty is the correct handling of the continuous part of our belief state approximation. The reason is that after collapsing a mixture of Gaussians, updating the distribution of each component based only on evidence relative to the result of the collapse is a non-trivial problem. Fortunately, we are primarily interested in getting a more informed posterior for the hypothesis variable, since our main goal is simply to identify the most likely hypotheses. The continuous parts will typically track correctly if we identify the correct hypotheses. Therefore, we execute smoothing only for the discrete variables.
  </subsection>
  <subsection id="2535.4.25">
   The process is now easy; assume that we use a lookahead window of ` time slices (thus, the last observation we get to see is t + ` + 1). The backward message to time step t +`0 is simply the probability of yt+` 0 +1;:::;yt+`+1 given Ht+` 0 . This message defines a posterior distribution over Ht+` 0 , which can be computed using standard methods.
  </subsection>
  <subsection id="2535.4.26">
   We now use our collapsing matrix to compute the effect of this new information on Dt+l 0 and Ht+l 0 ,1. In particular, the probabilitiesof all the components which were collapsed into some ht+` 0 are multipliedby the change in the probability of ht+` 0 . This is also intuitivelyappealing — since all the collapsed components were similar, we should change their probabilities by the same factor. The result is a message to time step t +`0 ,1, which is propagated in the same way.
  </subsection>
  <subsection id="2535.4.27">
   When the process terminates at time step t, we have the probability P(Ht j y1;:::;yt+`+1), which we can then use to better guide which hypotheses to eliminate, as well as our collapsing algorithm. We note, however, that the results of smoothing should be used only for guiding the approximation. In order to avoid double-counting evidence, it is very important to continue our tracking using our unsmoothed hypothesis weights t (Ht ).
  </subsection>
  <subsection id="2535.4.28">
   Subsystem decomposition One of the underlying assumptions of the algorithm is that it is feasible to enumerate all the possible instantiations of the discrete variables Dt . Unfortunately, for non-trivial systems, this assumption is often unrealistic. The number of possible instantiations of the discrete variables Dt grows exponentially with the number of discrete variables in the system. To deal with this problem, we take an approach introduced for discrete systems in (Boyen  Koller 1998).
  </subsection>
  <subsection id="2535.4.29">
   The crucial idea is to make use of the fact that large systems are typically composed of subsystems, and that, while the subsystems are correlated, the interaction between them is often not so strong. Therefore, it might be reasonable to approximate our beliefs about the system using separate beliefs about the subsystems, i.e., using a belief state where they are independent. Note that this approximation is very different from one that ignores the interactions between the subsystems. As we do the propagation, the state of one subsystem can influence the state of another; but we then decouple the correlations resulting from this interaction when we maintain our beliefs about the current system state.
  </subsection>
  <subsection id="2535.4.30">
   More precisely, we partition the system variables into n disjoint sets, corresponding to the different subsystems. Let Di and Xi be the discrete and continuous variables in subsystem i, respectively. As for the case of a single system, we represent the belief state for each subsystem i as a mixture, represented using a hypothesis variable Hi . We also associate with each subsystem a set of observation variables Yi , which are the ones that are most relevant to the subsystem.
  </subsection>
  <subsection id="2535.4.31">
   Our goal is to get a belief state t i over each subsystem i.
  </subsection>
  <subsection id="2535.4.32">
   Since subsystem i may be influenced directly by some other subsystems, we cannot perform the inference completely in isolation inside subsystem i. Instead, we consider the extended subsystem which includes subsystem i, and all the variables from other subsystems which influence it.
  </subsection>
  <subsection id="2535.4.33">
   Given our belief state representation, it is possible to describe the distributionover the extended subsystem as a mixture of Gaussians. As in the single subsystem case, we can introduce evidence which changes our probability distribution over discrete variables as well as over continuous variables. Note that different extended subsystems may overlap, and after introducing different measurements into these subsystems we may have a different distribution over the shared variables. We synchronize these probabilities using a message-passing algorithm called calibration (Lauritzen  Spiegelhalter 1988). As in backward propagation, we only update the discrete variables, not the continuous ones. As a result of this phase, all the discrete variables are updated using all the measurement information. This is important, as outside evidence can be important in determining the likelihood of the different hypotheses.
  </subsection>
  <subsection id="2535.4.34">
   It is also possible to modify the smoothing algorithm to use the decomposed representation of the belief state. The collapsing is done independently in every subsystem using the same algorithm (and giving a collapsing matrix for every subsystem). The backward messages are used to update the hypothesis variables of each one of the subsystems. The information can be propagated backwards with the collapsing matrices. The only difference is that after this propagation, F50 R10 R12 R23 R34 R45 R50 F10 F12 F23 F34 F45 P1 P2 P3 P4 P5 Tank 1 Tank 2 Tank 3 Tank 4 Tank 5 = Measurement subsystem 5 subsystem 4 subsystem 2 subsystem 1 subsystem 3 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2 0 5 10 15 20 25 30 Conductance Time steps R12 Truth R12 Belief R45 Truth R45 Belief R23 Truth R23 Belief Figure 3: Five tank system and results we need to calibrate the discrete variables of the subsystems, just like in the forward pass.
  </subsection>
 </paragraph>
 <paragraph id="2535.5" name="Experimental Results">
  <subsection id="2535.5.1">
   We tested our algorithm on a system which contains five water tanks, shown in Figure 3. The system contains six conductances and five pressures, which are all free parameters, but only three measurements, making it a challenging system to track. In addition, the system contains the three types of failures described in Section : drifts, bursts and measurement errors, each occurring with probability 0:001. Thus, at every time step every conductance has 4 possible failure modes (stable, fault, buildup, leak) and each measurement has 2 possible failure modes. Counting all the possible failures at time t + 1 and the persistent failures from time t, the system has 227 possible failure modes at any point in time, eliminating any hope of using inference without some decomposition of the system.
  </subsection>
  <subsection id="2535.5.2">
   In our experiments we decomposed the system into five subsystems, since decompositions into less subsystems demanded too much memory. Each tank was considered to be a subsystem (see Figure 3). We tracked five hypotheses per subsystem, with a lookahead of two steps when doing smoothing. We tested our algorithm on a complicated sequence:  At t = 5, R23 starts to experience a negative drift.
  </subsection>
  <subsection id="2535.5.3">
   At t = 10, we introduce two simultaneous measurement errors in the measurements of F23 and F5o.
  </subsection>
  <subsection id="2535.5.4">
   At t = 13, R23 bursts, and then returns to a steady state.
  </subsection>
  <subsection id="2535.5.5">
   At t = 17R45 starts a negative drift.
  </subsection>
  <subsection id="2535.5.6">
   At t = 23R45 bursts and then returns to normal.
  </subsection>
  <subsection id="2535.5.7">
   At t = 25R12 bursts.
  </subsection>
  <subsection id="2535.5.8">
   The graph in Figure 3 shows the results of tracking R23,  R45 and R12. Initially, at t = 5 the effect of the drift in R23 was negligible. The corresponding hypothesis had a probability of 0:012%, but after smoothing the probability went up to 7:43%. As a result our algorithm considered this a likely hypothesis, and kept it in the belief state. At t = 6the probabilityof a negative drift went from 71:7%to 99:9%after smoothing. At this point our algorithm correctly detected the negative drift, and maintained a very high probabilityfor this event until t = 13. At this point, before smoothing, our algorithm considered two hypotheses: a burst in R23 (probability 57%) or the persistence of the negative drift and a measurement failure (probability 43%). Smoothing raised the probability of a burst (the correct hypothesis) to 100%.
  </subsection>
  <subsection id="2535.5.9">
   The actual values of R23 were tracked with high accuracy.
  </subsection>
  <subsection id="2535.5.10">
   The measurement of F23 made the tracking of R23 a relatively simple problem. Things are much more complicated for R45. Not only is there no direct measurement of F45, there is no measurement at all in subsystem 4! Therefore, tracking R45 is a real challenge. Due to lack of space we omit the actual numbers, but in this run our algorithm detected the drift as soon as it began. (In other runs the detection was sometimes delayed by 2–3 steps.) It is also interesting to see the behavior of R45 during the burst. Our algorithm detected the burst, but since no evidence is used in subsystem 4 it could not track the true value of the burst correctly. We plan to address this problem in future work by propagating continuous information between the subsystems as well as discrete information.
  </subsection>
  <subsection id="2535.5.11">
   For the measurements failures at t = 10, our algorithm behaved in almost the same way for the two measurements, so we report on M23 only. Before smoothing, our algorithm considered two hypotheses — a burst in R23 (probability 81:8%)or a measurement fault and a persistent negative drift in R23 (probability 18:2%). After smoothing the probability of the correct hypothesis went up to almost 100%.
  </subsection>
  <subsection id="2535.5.12">
   We feel that these results demonstrate the power of our algorithm, and its ability to correctly diagnose and track even a complex system with a small number of measurements.
  </subsection>
 </paragraph>
 <paragraph id="2535.6" name="Conclusions and future work">
  <subsection id="2535.6.1">
   In this paper, we presented a new approach for monitoring and diagnosis of hybrid systems. We model these systems as DBNs, thus reducing the problem of diagnosis to the problem of tracking. It is not a surprise that tracking hybrid systems is also a difficult problem. In this paper we focus on a special class of hybrid systems: ones that given some particular assignment to the discrete variables have linear dynamics (or can be linearized with a satisfactory precision).
  </subsection>
  <subsection id="2535.6.2">
   Furthermore, we focus on systems that are composed of several weakly interacting subsystems. We believe that many real-life physical systems belong to this class of systems.
  </subsection>
  <subsection id="2535.6.3">
   We present a novel tracking algorithm for this class of systems. First, we collapse similar hypotheses instead of just choosing the most likely ones. This technique allows us to use a bounded window look-ahead into the future. We use future observations to assist us in determining which hypotheses are the likelycandidates and should be kept relative unchanged, and which are less likely and can be collapsed more aggressively. Our final contribution is introducing a way to avoid the exponential blowup, caused by many discrete variables within a time slice. We do this by reasoning separately about the different subsystems, while still propagating correlations between them.
  </subsection>
  <subsection id="2535.6.4">
   Our initial experiments with this approach are very encouraging. We have tested it on a very large system (one with 227 different discrete states per time slice), with a particularly difficult scenario. Our algorithm found most of the faults, showing that it can be used to provide reliable tracking and diagnosis even for very hard problems. Of course, we plan to conduct further experiments in other domains.
  </subsection>
  <subsection id="2535.6.5">
   We are currently working on extending the calibration algorithm to allow us to propagate information between subsystems not only for the discrete variables but for continuous variables as well. We believe that this new feature will significantly improve our tracking capabilities, especially on long sequences with many events.
  </subsection>
  <subsection id="2535.6.6">
   We are also looking for ways to extend the algorithm beyond the family of conditional linear systems (or systems which can be approximated as such). In particular, we hope to be able to handle discrete children of continuous parents and highly non-linear evidence models.
  </subsection>
  <subsection id="2535.6.7">
   Finally, we hope to apply our algorithm on real-life applications and not just on synthetic data. We are exploring possible applications in the diagnosis domain, such as monitoring the performance of an engine, as well as application in other domains, such as visual tracking.
  </subsection>
  <subsection id="2535.6.8">
   Acknowledgments. This research was supported by an ONR Young Investigator Award grant number N00014-991-0464 and by ARO under the MURI program, “Integrated Approach to Intelligent Systems,” grant number DAAH0496-1-0341, and by the Terman Foundation.
  </subsection>
 </paragraph>
 <paragraph id="2535.7" name="References">
  <subsection id="2535.7.1">
   Bar-Shalom, Y., and Fortmann, T. E. 1988. Tracking and Data Association. Academic Press.
  </subsection>
  <subsection id="2535.7.2">
   Boyen, X., and Koller, D. 1998. Tractable inference for complex stochastic processes. In Proc. UAI.
  </subsection>
  <subsection id="2535.7.3">
   Cover, T., and Thomas, J. 1991. Elements of Information Theory.
  </subsection>
  <subsection id="2535.7.4">
   Wiley.
  </subsection>
  <subsection id="2535.7.5">
   Hamscher, W.; Console, L.; and de Kleer (eds.), J. 1992. Readings in Model-Based Diagnosis. Morgan Kaufmann.
  </subsection>
  <subsection id="2535.7.6">
   Isermann, R. 1997. Supervision, fault-detection and faultdiagnosis methods an introduction. Control Engineering Practice 5(5):639–652.
  </subsection>
  <subsection id="2535.7.7">
   Kalman, R. 1960. A new approach to linear filtering and prediction problems. J. of Basic Engineering 82:34–45.
  </subsection>
  <subsection id="2535.7.8">
   Lauritzen, S., and Spiegelhalter, D. 1988. Local computations with probabilities on graphical structures and their application to expert systems. J. Roy. Stat. Soc. B 50.
  </subsection>
  <subsection id="2535.7.9">
   McIlraith, S.; Biswas, G.; Clancy, D.; and Gupta, V. 2000. Hybrid systems diagnosis. In Proceedings of Hybrid Systems: Computation and Control, Lecture Notes in Computer Science. Berlin Heidelberg New York: Springer-Verlag. 282–295.
  </subsection>
  <subsection id="2535.7.10">
   Mosterman, P. J., and Biswas, G. 1997. Monitoring, prediction, and fault isolation in dynamic physical systems. In Proc. AAAI97, 100–105.
  </subsection>
  <subsection id="2535.7.11">
   Rosenberg,R. C., and Karnopp, D. 1983. Introduction to Physical System Dynamics. McGraw-Hill.
  </subsection>
 </paragraph>
</paper>