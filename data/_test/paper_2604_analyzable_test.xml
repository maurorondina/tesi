<?xml version="1.0" encoding="utf-8"?>
<paper id="2604" url="http://www.aaai.org/Papers/AAAI/2000/AAAI00-025.pdf">
 <title id="2604.0" name="DATALOG with Constraints — An Answer-set Programming System"/>
 <subsection id="2604.0.1">
  Deborah East and Mirosław Truszczyński Department of Computer Science University of Kentucky Lexington KY 40506-0046, USA email: deastjmirek@cs.uky.edu
 </subsection>
 <paragraph id="2604.1" name="Abstract">
  <subsection id="2604.1.1">
   Answer-set programming (ASP) has emerged recently as a viable programming paradigm well attuned to search problems in AI, constraint satisfaction and combinatorics. Propositional logic is, arguably, the simplest ASP system with an intuitive semantics supporting direct modeling of problem constraints. However, for some applications, especially those requiring that transitive closure be computed, it requires additional variables and results in large theories. Consequently, it may not be a practical computational tool for such problems.
  </subsection>
  <subsection id="2604.1.2">
   On the other hand, ASP systems based on nonmonotonic logics, such as stable logic programming, can handle transitive closure computation efficiently and, in general, yield very concise theories as problem representations. Their semantics is, however, more complex. Searching for the middle ground, in this paper we introduce a new nonmonotonic logic, DATALOG with constraints or DC. Informally, DC theories consist of propositional clauses (constraints) and of Horn rules.
  </subsection>
  <subsection id="2604.1.3">
   The semantics is a simple and natural extension of the semantics of the propositional logic. However, thanks to the presence of Horn rules in the system, modeling of transitive closure becomes straightforward. We describe the syntax and semantics of DC, and study its properties. We discuss an implementation of DC and present results of experimental study of the effectiveness of DC, comparing it with the csat satisfiability checker and smodels implementation of stable logic programming. Our results show that DC is competitive with the other two approaches, in case of many search problems, often yielding much more efficient solutions.
  </subsection>
  <subsection id="2604.1.4">
   Content Areas: constraint saitsfaction, search, knowledge representation, logic programming, nonmonotonic reasoning.
  </subsection>
 </paragraph>
 <paragraph id="2604.2" name="Introduction">
  <subsection id="2604.2.1">
   Many important computational problems in combinatorial optimization, constraint satisfaction and artificial intelligence can be cast as search problems. Answer-set programming (ASP) (Marek &amp; Truszczyński 1999; Niemela 1998) was recently identified as a declarative programming paradigm appropriate for such applications. Logic programCopyright c 2000, American Association for Artificial Intelligence (www.aaai.org). All rights reserved.
  </subsection>
  <subsection id="2604.2.2">
   ming with the stable-model semantics (stable logic programming, for short) was proposed as an embodiment of this paradigm. Disjunctive logic programming with the answerset semantics is another implementation of ASP currently under development (Eiter et al. 1998). Early experimental results demonstrate the potential of answer-set programming approaches in such areas as planning and constraint satisfaction (Niemela 1998; Lifschitz 1999a; 1999b).
  </subsection>
  <subsection id="2604.2.3">
   In this paper we describe another formalism that implements the ASP approach. We call it DATALOG with constraints and denote by DC. Our goal is to design an ASP system with a semantics more readily understandable than the semantics of stable models. We seek a semantics that would be as close as possible to propositional satisfiability yet as expressive and as effective, especially from the point of view of conciseness of representations and time performance, as the stable logic programming. We argue that DC has a potential to become a practical declarative programming tool. We show that it yields intuitive and small-size encodings, we characterize its complexity and expressive power and present computational experiments demonstrating its effectiveness.
  </subsection>
  <subsection id="2604.2.4">
   Answer-set programming is a paradigm in which programs are built as theories in some formal system F with a well-defined syntax, and with a semantics that assigns to a theory P in the system a collection of subsets of some domain. These subsets are referred to as answer sets of P and specify the results of computation based on P. To solve a problem  in an ASP formalism, we find a program P so that the solutions to  can be reconstructed, in polynomial (ideally, linear) time, from the answer sets to P.
  </subsection>
  <subsection id="2604.2.5">
   The definition of the answer-set programming given above is very general. Essentially any logic formalism can be a basis for an answer-set programming system. For instance, the propositional logic gives rise to an ASP system: programs are collections of propositional clauses, their models are answer sets. To solve, say, a planning problem, we encode the constraints of the problem as propositional clauses in such a way that legal plans are determined by models of the resulting propositional theory. This approach, called satisfiability planning, received significant attention lately and was shown to be quite effective (Kautz  Selman 1992; 1996; Kautz, McAllester,  Selman 1996).
  </subsection>
  <subsection id="2604.2.6">
   Recently, several implementations of the ASP approach From: AAAI-00 Proceedings. Copyright © 2000, AAAI (www.aaai.org). All rights reserved.
  </subsection>
  <subsection id="2604.2.7">
   were developed that are based on nonmonotonic logics such as smodels (Niemela  Simons 1996), for stable logic programming, dlv (Eiter et al. 1998), for disjunctive logic programming with answer-set semantics, and deres (Cholewiński, Marek,  Truszczyński 1997), for default logic with Reiter’s extensions. All these systems have been extensively studied. Promising experimental results concerning their performance were reported (Cholewiński et al.
  </subsection>
  <subsection id="2604.2.8">
   1999; Eiter et al. 1998; Niemela 1998).
  </subsection>
  <subsection id="2604.2.9">
   The question arises which formal logics are appropriate as bases of answer-set programming implementations. To discuss such a general question one needs to formulate quality criteria with respect to which ASP systems can be compared.
  </subsection>
  <subsection id="2604.2.10">
   At the very least, these criteria should include: 1. expressive power 2. time performance 3. simplicity of the semantics 4. ease of coding, conciseness of programs.
  </subsection>
  <subsection id="2604.2.11">
   We will discuss these criteria in detail elsewhere. We will make here only a few brief comments on the matter.
  </subsection>
  <subsection id="2604.2.12">
   From the point of view of the expressive power all the systems that we discussed are quite similar. Propositional logic and stable logic programming are well-attuned to the class NP (Schlipf 1995). Disjunctive logic programming and default logic capture the class 2 P (Eiter  Gottlob 1995; Cadoli, Eiter,  Gottlob 1997). However, this distinction is not essential as recently pointed out in (Janhunen et al.
  </subsection>
  <subsection id="2604.2.13">
   2000). The issue of time performance can be resolved only through comprehensive experimentation and this work is currently under way.
  </subsection>
  <subsection id="2604.2.14">
   As concerns inherent complexity of the system and intuitiveness of the semantics, ASP systems based on the propositional logic seem to be clear winners. However, propositional logic is monotone and modeling indefinite information and phenomena such as the frame problem is not quite straightforward. In applications involving the computation of transitive closures, as in the problem of existence of hamilton cycles, it leads to programs that are large and, thus, difficult to process. In this respect, ASP systems based on nonmonotonic logics have an edge. They were designed to handle incomplete and indefinite information. Thus, they often yield more concise programs. However, they require more elaborate formal machinery and their semantics are more complex.
  </subsection>
  <subsection id="2604.2.15">
   Searching for the middle ground between systems such as logic programming with stable model semantics and propositional logic, we propose here a new ASP formalism, DC.
  </subsection>
  <subsection id="2604.2.16">
   Our guiding principle was to design a system which would lead to small-size encodings, believing that small theories will lead to more efficient solutions. We show that DC is nonmonotonic, has the same expressive power as stable logic programming but that its semantics stays closer to that of propositional logic. Thus, it is arguably simpler than the stable-model semantics. We present experimental results that demonstrate that DC is competitive with ASP implementations based on nonmonotonic logics (we use smodels for comparison) and those based on propositional logics (we use csat (Dubois et al. 1996) in our experiments). Our results strongly indicate that formalisms which provide smaller-size encodings are more effective as practical search-problem solvers.
  </subsection>
 </paragraph>
 <paragraph id="2604.3" name="DATALOG with constraints" label="Problem">
  <subsection id="2604.3.1">
   A DC theory (or program) consists of constraints and Horn rules (DATALOG program). This fact motivates out choice of terminology — DATALOG with constraints. We start a discussion of DC with the propositional case. Our language is determined by a set of atoms At. We will assume that At is of the form At = AtC [ AtH, where AtC and AtH are disjoint.
  </subsection>
  <subsection id="2604.3.2">
   A DC theory (or DC program) is a triple T = (TC;TH;TPC), where 1. TC is a set of propositional clauses :a1 _ ::: _ :am _ b1 _:::_bn such that all ai and bj are from AtC, 2. TH is a set of Horn rules a1 ^ ::: ^ am ! b such that b 2 AtH and all ai are from At, 3. TPC is a set of clauses over At.
  </subsection>
  <subsection id="2604.3.3">
   By At(T), AtC(T)and AtPC(T)we denote the set of atoms from At, AtC and AtPC, respectively, that actually appear in T.
  </subsection>
  <subsection id="2604.3.4">
   With a DC theory T = (TC;TH;TPC) we associate a family of subsets of AtC(T). We say that a set M  AtC(T) satisfies T (is an answer set of T) if 1. M satisfies all the clauses in TC, and 2. the closure of M under the Horn rules in TH, Mc = LM(TH [M) satisfies all clauses in TPC (LM(P)denotes the least model of a Horn program P).
  </subsection>
  <subsection id="2604.3.5">
   Intuitively, the collection of clauses in TC can be thought of as a representation of the constraints of the problem, Horn rules in TH can be viewed as a mechanism to compute closures of sets of atoms satisfying the constraints in TC, and the clauses in TPC can be regarded as constraints on closed sets (we refer to them as post-constraints). A set of atoms M  AtC(T) is a model if it (propositionally) satisfies the constraints in TC and if its closure (propositionally) satisfies the constraints in TPC. Thus, the semantics of DC retains much of the simplicity of the semantics of propositional logic.
  </subsection>
  <subsection id="2604.3.6">
   DC can be used as a computational tool to solve search problems. We define a search problem  to be determined by a set of finite instances, D, such that for each instance I 2 D, there is a finite set S(I) of all solutions to  for the instance I. For example, the problem of finding a hamilton cycle in a graph is a search problem: graphs are instances and for each graph, its hamilton cycles (sets of their edges) are solutions. A DC theory T = (TC;TH;TPC) solves a search problem  if solutions to  can be computed (in polynomial time) from answer sets to T. Propositional logic and stable logic programming are used as problem solving formalisms following the same general paradigm. To illustrate all the concepts introduced here and show how DCprograms can be built by modeling problem constraints, we will now present a DC program that solves the hamilton-cycle problem.
  </subsection>
  <subsection id="2604.3.7">
   Consider a directed graph G with the vertex set V and the edge set E. Consider a set of atoms fhc(a;b):(a;b) 2 Eg. An intuitive interpretation of an atom hc(a;b)is that the edge (a;b) is in a hamilton cycle. Include in TC all clauses  of the form :hc(b;a) _ :hc(c;a), where a;b;c 2 V , b 6= c and (b;a);(c;a) 2 E. In addition, include in TC all clauses of the form :hc(a;b) _ :hc(a;c), where a;b;c 2 V , b 6= c and (a;b);(a;c) 2 E. Clearly, the set of propositional variables of the form fhc(a;b):(a;b) 2 Fg, where F  E, satisfies all clauses in TC if and only if no two distinct edges in F end in the same vertex and no two distinct edges in F start in the same vertex. In other words, F spans a collection of paths and cycles in G.
  </subsection>
  <subsection id="2604.3.8">
   To guarantee that the edges in F define a hamilton cycle, we must enforce that all vertices of G are reached by means of the edges in F if we start in some (arbitrarily chosen) vertex of G. This can be accomplished by means of a simple Horn program. Let us choose a vertex, say s, in G. Include in TH the Horn rules hc(s;t) ! vstd(t), for every edge (s;t) in G. In addition, include in TH Horn rules vstd(t);hc(t;u) ! vstd(u), for every edge (t;u) of G not starting in s. Clearly, the least model of F [ TH, where F is a subset of E, contains precisely these variables of the form vstd(t) for which t is reachable from s by a nonempty path spanned by the edges in F. Thus, F is the set of edges of a hamilton cycle of G if and only if the least model of F [ TH, contains variable vstd(t) for every vertex t of G. Let us define TPC = fvstd(t):t 2 Vg and Tham(G) = (TC;TH;TPC). It follows that hamilton cycles of G can be reconstructed (in linear time) from answer sets to the DC theory Tham(G). In other words, to find a hamilton cycle in G, it is enough to find an answer set for Tham(G).
  </subsection>
  <subsection id="2604.3.9">
   This example illustrates the simplicity of the semantics — it is only a slight adaptation of the semantics of propositional logic to the case when in addition to propositional clauses we also have Horn rules in theories. It also illustrates the power of DC to generate concise encodings. All known propositional encodings of the hamilton-cycle problem require that additional variables are introduced to “count” how far from the starting vertex an edge is located. Consequently, propositional encodings are much larger and lead to inefficient computational approaches to the problem. We present experimental evidence to this claim later in the paper.
  </subsection>
  <subsection id="2604.3.10">
   The question arises which search problems can be represented (and solved) by means of finding answer sets to appropriate DC programs. In general, the question remains open. We have an answer, though, if we restrict our attention to the special case of decision problems. Consider a DCtheory T = (TC;TH;TPC), where TH = TPC = ;. Clearly, M is an answer set for T if and only if M is a model of the collection of clauses TC. Thus, the problem of existence of an answer set is at least as hard as the propositional satisfiability problem. On the other hand, for every DC theory T and for every set M  AtC(T), it can be checked in linear time whether M is an answer set for T. Thus, we obtain the following complexity result.
  </subsection>
  <subsection id="2604.3.11">
   Theorem 1 The problem of existence of an answer set for a finite propositional DC theory T is NP-complete.
  </subsection>
  <subsection id="2604.3.12">
   It follows that every problem in NP can be polynomially reduced to the problem of existence of an answer set for a propositional DC program. Thus, given a problem  in NP, for every instance I of ,  can be decided by deciding the existence of an answer set for the DC program corresponding to  and I.
  </subsection>
  <subsection id="2604.3.13">
   Propositional DC can be extended to the predicate case.
  </subsection>
  <subsection id="2604.3.14">
   It is important as it significantly simplifies the task of developing programs for solving problems with DC. In the example discussed above, the theory Tham(G) depends heavily on the input. Each time we change the input graph, a different theory has to be used. However, when constructing predicate DC-based solutions to a problem , it is often possible to separate the representation of an instance (input) to  from that of the constraints that define . As a result only one (predicate) program describing the constraints of  needs to be written. Specific input for the program, say I, can be described separately as a collection of facts (according to some uniform schema). Both parts together can be combined to yield a DC program whose answer sets determine solutions to  for the input I. Such an approach, we will refer to it as uniform, is often used in the context of DATALOG, DATALOG: or logic programming to study complexity of these systems as query languages. The part representing input is referred to as the extensional database.
  </subsection>
  <subsection id="2604.3.15">
   The part representing the query or the problem is called the intensional database or program. Due to the space limitations we do not discuss the details of the predicate case here.
  </subsection>
  <subsection id="2604.3.16">
   They will be given in the full version of the paper. We only state a generalization of Theorem 1.
  </subsection>
  <subsection id="2604.3.17">
   Theorem 2 The expressive power of DC is the same as that of stable logic programming. In particular, a decision problem  can be solved uniformly in DC if and only if  is in the class NP.
  </subsection>
 </paragraph>
 <paragraph id="2604.4" name="Implementation">
  <subsection id="2604.4.1">
   Some types of constraints appear frequently in applications. For instance, when defining plans we may want to specify a constraint that says that exactly one action from the set of allowed actions be selected at each step. Such constraints can be modeled by collections of clauses. To make sure DC programs are as easy to write and as concise as possible we have extended the syntax of DC by providing explicit ways to model constraints of the form “select at least (at most, exactly) k elements from a set”. Having these constraints results in shorter programs which, as we believe, has a significant positive effect of the performance of our system.
  </subsection>
  <subsection id="2604.4.2">
   An example of a select constraint with a short explanation is presented here. Let PRED be the set of predicates occurring in the IDB. For each variable X declared in the IDB the range R(X) of X is determined by the EDB.
  </subsection>
  <subsection id="2604.4.3">
   Select(n;m; ~ Y;p1(~ X);:::;pi(~ X; ~ Y))q( ~ X; ~ Y ), where n;m are nonnegative integers such that n  m;q 2 PRED and p1;:::;pi are EDB predicates or logical conditions (logical conditions can be comparisons of arithmetic expressions or string comparisons). The interpretation of this constraint is as follows: for every ~ x 2 R(~ X) at least n atoms and at most m atoms in the set fq(~ x;~ y) : ~ y 2 R(~ Y)g are true.
  </subsection>
  <subsection id="2604.4.4">
   We implemented DC in the predicate setting. Thus, our system consists of two main modules. The first of them, referred to as grounder, converts a predicate DC program (consisting of both the extensional and intensional parts) into the corresponding propositional DC program. The second module, DC solver, denoted dcs, finds the answer sets to propositionalDCprograms. Since we focus on the propositional case here, we only describe the key ideas behind the DC solver, dcs.
  </subsection>
  <subsection id="2604.4.5">
   The DC solver uses a Davis-Putnam type approach, with backtracking, propagation and lookahead (also called literal testing), to deal with constraints represented as clauses, select constraints and Horn rules, and to search for answer sets. The lookahead in DC is similar to local processing performed in csat (Dubois et al. 1996). However, we use different methods to determine how many literals to consider in the lookahead phase. Other techniques, especially propagation and search heuristics, were designed specifically for the case of DC as they must take into account the presence of Horn rules in programs.
  </subsection>
  <subsection id="2604.4.6">
   The lookahead procedure selects a number of literals which have not yet been assigned a value. For each such literal, the procedure tries both truth values: true and false.
  </subsection>
  <subsection id="2604.4.7">
   For each assignment, the theory is evaluated using propagation. If in both cases a contradiction is reached, then it is necessary to backtrack. If for only one evalution a conflict is reached, then the literal is assigned the other truth value and we proceed to the next step. If neither evaluation results in a contradiction, we cannot assign a truth value to this literal but we save the data such as the number of forced literals and the number of clauses satisfied, computed during propagation.
  </subsection>
  <subsection id="2604.4.8">
   Clearly, if all unassigned literals were tested it would prune the most search space. At the same time, the savings might not be large enough to compensate for the increase in the running time caused by extensive lookahead. Thus, we select only a portion of all unassigned literals for lookahead.
  </subsection>
  <subsection id="2604.4.9">
   The number of literals to consider was established empirically (it does not depend on the size of the theory). Since not all literals are selected, it is important to focus on those literals that are likely to result in a contradiction for at least one of the truth values. In our implementation, we select the most constrained literals, as determined by their weights.
  </subsection>
  <subsection id="2604.4.10">
   Specifically, each constraint is assigned a weight based on its current length and types (recall that in addition to propositional clauses, we also allow other types of constraints, e.g., select constraints). The shorter the constraint the greater its weight. Also, certain types of constraints force more assignments on literals and are given a greater weight than other constraints of the same length. Every time a literal appears in an unsatisfied constraint, the weight of that literal is incremented by the weight of the clause.
  </subsection>
  <subsection id="2604.4.11">
   After testing a predetermined number of literals without finding a forced truth assignment and without backtracking, the information computed during propagation is used to choose the next literal for which both possible truth assignments have to be tested (branching literal). The choice of the next branching literal is based on an approximation of which literal, once assigned a truth value, will force the truth Hamilton cycle; log scale 1 .1 100 10 70 .01 N u m b e r o f V e r t i c e s 50 60 80 30 40 smodels S e c o n d s 1000 dcs csat Figure 1: Hamilton cycle problem; times on the log scale as function of the number of vertices.
  </subsection>
  <subsection id="2604.4.12">
   assignments onto the largest number of other literals and will satisfy the largest number of clauses. Using the data computed during propagation gives more accurate information on which to base such approximations. The methods used for determining which literals to select in the lookahead and which data to collect and save during the propagation phase are two key ways in which the literal testing procedure differs from the local processing of csat.
  </subsection>
 </paragraph>
 <paragraph id="2604.5" name="Experimentation">
  <subsection id="2604.5.1">
   We compared the performance of DC solver dcs with smodels, a system for computing stable models of logic programs (Niemela  Simons 1996), and csat, a system for testing propositional satisfiability (Dubois et al. 1996).
  </subsection>
  <subsection id="2604.5.2">
   In the case of smodels we used version 2.24 in conjunction with the grounder lparse, version 0.99.41. These versions of lparse and smodels implement the expressive rules described by (Simons 1999). The expressive rules were used whenever applicable during the testing. The programs were all executed on a Sun SparcStation 20. For each test we report the cpu user times for processing the corresponding propositional program or theory. We tested all three system to compute hamilton cycles and colorings in graphs, to solve the N-queens problem, to prove that the pigeonhole problem has no solution if the number of pigeons exceeds the number of holes, and to compute Schur numbers.
  </subsection>
  <subsection id="2604.5.3">
   The Hamilton cycle problem has already been described.
  </subsection>
  <subsection id="2604.5.4">
   We randomly generated one thousand graphs with the edgeto-vertex ratio such that  50% of the graphs contained Hamilton cycles (crossover region). The number of vertices ranged from 30 to 80. We used encodings of the problem as a DC program, logic program (in smodels syntax) and as a propositional theory. dcs performed better than smodels and smodels performed significantly better than csat (Fig. 1). We believe that a major factor behind poorer performance of csat is that all known propositional encodings of the hamilton cycle problem are much larger than those possible with DC or logic programs (under the stable model semantics). Propositional encodings, due to their size, rendered csat not practical to execute for graphs with more than 40 vertices.
  </subsection>
  <subsection id="2604.5.5">
   The N-queens problem consists of finding a placement  1 .1 1000 100 10 .01 8 10 12 14 16 18 N Q U E E N S 20 smodels s d n o c e S dcs csat Figure 2: N-queens problem; log scale B-N csat dcs smodel b-n sec sec sec 3-13 0.03 0.00 0.12 3-14 0.05 0.00 0.16 4-14 0.05 0.01 0.23 4-43 0.59 1.91 5.23 4-44 1.95 51.04 5.55 4-45 1599.92 226.44 12501.00 Figure 3: Schur problem; times and the number of choice points.
  </subsection>
  <subsection id="2604.5.6">
   of N queens on an N  N board such that no queen can remove another. Both csat and dcs execute in much less time than smodels for these problems (Fig. 2). Again the size of the encoding seems to be a major factor. One thing to consider in this case is that the number of rules for smodels is approximately five times that for DC and more than twice that of propositional encodings.
  </subsection>
  <subsection id="2604.5.7">
   The Schur problem consists of placing N numbers 1;2;:::;N in B bins such that no bin is closed under sums.
  </subsection>
  <subsection id="2604.5.8">
   That is, for all numbers x, y, z, 1  x;y;z  N, if x and y are the same bin, then z is not (x and y need not be distinct). The Schur number S(B) is the maximum number N for which such a placement is still possible. It is known to exist for every B  1. We considered the problem of the existence of the placement for B = 3 and N = 13 and 14, and for B = 4 and N = 43;44 and 45. In each case we used all three systems to process the corresponding encodings. The results are shown in Fig. 3. It follows that S(3) = 13 and S(4) = 44. Again, dcs outperforms both smodels and csat.
  </subsection>
  <subsection id="2604.5.9">
   Results for graph 3-coloring for graphs with the number of vertices ranging from 50 to 300 are shown in Fig. 4 (for every choice of the number of vertices, 100 graphs from the crossover region were randomly generated). Both dcs and csat performed better than smodels. Again the size of the theory seems to be a factor. The CNF theory for coloring is smaller than a logic program encoding the same problem.
  </subsection>
  <subsection id="2604.5.10">
   The sizes of propositional and DC encodings are similar.
  </subsection>
  <subsection id="2604.5.11">
   Results for the pigeonhole placement problem show a similar performance of all three algorithms, with csat do3-coloring: log scale 1 .1 100 10 250 .01 150 200 300 100 50 smodels N u m b e r o f V e r t i c e s s d n o c e S 1000 dcs csat Figure 4: 3-coloring problem; log scale.
  </subsection>
  <subsection id="2604.5.12">
   1 .1 1000 100 10 .01 6/6 P i g e o n / H o l e s 10/9 9/8 8/7 7/6 smodels s n d o c e S dcs csat Figure 5: Pigeonhole problem; log scale.
  </subsection>
  <subsection id="2604.5.13">
   ing slightly better than the others and dcs outperforming (again only slightly) smodels.
  </subsection>
 </paragraph>
 <paragraph id="2604.6" name="Conclusions">
  <subsection id="2604.6.1">
   We described a new system, DC, for solving search problems. We designed DC so that its semantics was as close as possible to that of propositional logic. Our goal was to design a system that would result is short problem encodings. Thus, we provided constructs for some frequently occurring types of constraints and we built into DCelements of nonmonotonicity by including Horn rules in the syntax. As a result, DC programs encoding search problems are often much smaller than those possible with propositional theories. Experimental results show that dcs often outperforms systems based on propositional satisfiability as well as systems based on nonmonotonic logics, and that it constitutes a viable approach to solving problems in AI, constraint satisfaction and combinatorial optimization. We believe that our focus on short programs is the key to the success of DC and its reasoning engine dcs. Our results show that when building general purpose solvers of search problems, the size of encodings should be a key design factor.
  </subsection>
 </paragraph>
 <paragraph id="2604.7" name="References">
  <subsection id="2604.7.1">
   Cadoli, M.; Eiter, T.; and Gottlob, G. 1997. Default logic as a query language. IEEE Transactions on Knowledge and Data Engineering 9(3):448–463.
  </subsection>
  <subsection id="2604.7.2">
   Cholewiński, P.; Marek, W.; Mikitiuk, A.; and Truszczyński, M. 1999. Computing with default logic.
  </subsection>
  <subsection id="2604.7.3">
   Artificial Intelligence 112:105–146.
  </subsection>
  <subsection id="2604.7.4">
   Cholewiński, P.; Marek, W.; and Truszczyński, M. 1997.
  </subsection>
  <subsection id="2604.7.5">
   Default reasoning system deres. In Proceedings of KR-96, 512–528. Morgan Kaufman.
  </subsection>
  <subsection id="2604.7.6">
   Dubois, O.; Andre, P.; Boufkhad, Y.; and Carlier, J. 1996.
  </subsection>
  <subsection id="2604.7.7">
   Sat versus unsat. DIMACS Cliques, Coloring and Satisfiability 26.
  </subsection>
  <subsection id="2604.7.8">
   Eiter, T., and Gottlob, G. 1995. Computing with default logic. Annals of Mathematics and Artificial Intelligence 15(3-4):289–323.
  </subsection>
  <subsection id="2604.7.9">
   Eiter, T.; Leone, N.; Mateis, C.; Pfeifer, G.; and Scarcello, F. 1998. A kr system dlv: Progress report, comparisons and benchmarks. In Proceedings of Sixth International Conference on Knowledge Representation and Reasoning (KR ’98), 406–417. Morgan Kaufman.
  </subsection>
  <subsection id="2604.7.10">
   Janhunen, T.; Niemelä, I.; Simons, P.; and You, J. 2000.
  </subsection>
  <subsection id="2604.7.11">
   Unfolding partiality and disjunctions in stable models semantics. manuscript.
  </subsection>
  <subsection id="2604.7.12">
   Kautz, H. A., and Selman, B. 1992. Planning as satisfiability. In Proceedings of the 10th European Conference on Artificial Intelligence.
  </subsection>
  <subsection id="2604.7.13">
   Kautz, H., and Selman, B. 1996. Pushing the envelope: Planning, propositional logic, and stochastic search. In Proccedings of the Thirteenth National Conference on Artificial Intelligence (AAAI-96).
  </subsection>
  <subsection id="2604.7.14">
   Kautz, H.; McAllester, D.; and Selman, B. 1996. Encoding plans in propositional logic. In Proceedings of the Fifth International Conference on Principles of Knowledge Representation and Reasoning (KR-96).
  </subsection>
  <subsection id="2604.7.15">
   Lifschitz, V. 1999a. Action languages, answer sets, and planning. In Apt, K.; Marek, W.; Truszczyński, M.; and Warren, D., eds., The Logic Programming Paradigm: a 25Year Perspective. Springer Verlag. 357–373.
  </subsection>
  <subsection id="2604.7.16">
   Lifschitz, V. 1999b. Answer set planning. In Proceedings of the 1999 International Conference on Logic Programming, 23–37. MIT Press.
  </subsection>
  <subsection id="2604.7.17">
   Marek, V., and Truszczyński, M. 1999. Stable models and an alternative logic programming paradigm. In Apt, K.; Marek, W.; Truszczyński, M.; and Warren, D., eds., The Logic Programming Paradigm: a 25-Year Perspective.
  </subsection>
  <subsection id="2604.7.18">
   Springer Verlag. 375–398.
  </subsection>
  <subsection id="2604.7.19">
   Niemela, I., and Simons, P. 1996. Efficient implementation of the well-founded and stable model semantics. In Proceedings of JICSLP-96. MIT Press.
  </subsection>
  <subsection id="2604.7.20">
   Niemela, I. 1998. Logic programs with stable model semantics as a constraint programming paradigm. In Proceedings of the Workshop on Computational Aspects of Nonmonotonic Reasoning, 72–79.
  </subsection>
  <subsection id="2604.7.21">
   Schlipf, J. 1995. The expressive powers of the logic programming semantics. Journal of the Computer Systems and Science 51(1):64–86.
  </subsection>
  <subsection id="2604.7.22">
   Simons, P. 1999. Extending the stable model semantics with more expressive rules. In Gelfond, M.; Leone, N.; and Pfeifer, G., eds., Proceedings of 5th International Conference, LPNMR ’99, volume 1730 of Lecture Notes in Artificial Intelligence, 305–316. Springer Verlag.
  </subsection>
 </paragraph>
</paper>