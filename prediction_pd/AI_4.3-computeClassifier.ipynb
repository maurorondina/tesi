{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Text-Clean Training Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_subsection</th>\n",
       "      <th>paragraph_name</th>\n",
       "      <th>text_subsection</th>\n",
       "      <th>label_subsection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2549.1.1</td>\n",
       "      <td>Abstract</td>\n",
       "      <td>work machin learn extract focus distinct subpr...</td>\n",
       "      <td>N_PD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2549.2.1</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>extract problem convert text newswir articl we...</td>\n",
       "      <td>N_PD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2549.2.2</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>increas import brought attent kind automat doc...</td>\n",
       "      <td>N_PD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2549.2.3</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>work focus learn approach requir linguist expl...</td>\n",
       "      <td>N_PD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2549.2.4</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>time work integr led need special wrapper proc...</td>\n",
       "      <td>N_PD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_subsection paragraph_name  \\\n",
       "0      2549.1.1       Abstract   \n",
       "1      2549.2.1   Introduction   \n",
       "2      2549.2.2   Introduction   \n",
       "3      2549.2.3   Introduction   \n",
       "4      2549.2.4   Introduction   \n",
       "\n",
       "                                     text_subsection label_subsection  \n",
       "0  work machin learn extract focus distinct subpr...             N_PD  \n",
       "1  extract problem convert text newswir articl we...             N_PD  \n",
       "2  increas import brought attent kind automat doc...             N_PD  \n",
       "3  work focus learn approach requir linguist expl...             N_PD  \n",
       "4  time work integr led need special wrapper proc...             N_PD  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset_path = \"./resources/lemmatizated_training_set.pkl\"\n",
    "dataset_path = \"./resources/stemmed_training_set.pkl\"\n",
    "df = pd.read_pickle(dataset_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_subsection</th>\n",
       "      <th>paragraph_name</th>\n",
       "      <th>text_subsection</th>\n",
       "      <th>label_subsection</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2549.1.1</td>\n",
       "      <td>Abstract</td>\n",
       "      <td>work machin learn extract focus distinct subpr...</td>\n",
       "      <td>N_PD</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2549.2.1</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>extract problem convert text newswir articl we...</td>\n",
       "      <td>N_PD</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2549.2.2</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>increas import brought attent kind automat doc...</td>\n",
       "      <td>N_PD</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2549.2.3</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>work focus learn approach requir linguist expl...</td>\n",
       "      <td>N_PD</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2549.2.4</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>time work integr led need special wrapper proc...</td>\n",
       "      <td>N_PD</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132703</th>\n",
       "      <td>101131.17.2</td>\n",
       "      <td>C REPRODUCIBILITY</td>\n",
       "      <td>review confer paper iclr main task network rew...</td>\n",
       "      <td>N_PD</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132711</th>\n",
       "      <td>101144.2.6</td>\n",
       "      <td>1. Introduction</td>\n",
       "      <td>approach preserv spatial spectral tempor struc...</td>\n",
       "      <td>PD</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132712</th>\n",
       "      <td>101144.2.7</td>\n",
       "      <td>1. Introduction</td>\n",
       "      <td>increas effort automat detect phase start time...</td>\n",
       "      <td>PD</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132713</th>\n",
       "      <td>101144.2.8</td>\n",
       "      <td>1. Introduction</td>\n",
       "      <td>sampl data descript data numer eeg read partic...</td>\n",
       "      <td>PD</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132742</th>\n",
       "      <td>101144.7.1</td>\n",
       "      <td>6. Acknowledgements</td>\n",
       "      <td>thank auton lab professor artur dubrawski prov...</td>\n",
       "      <td>PD</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96380 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_subsection       paragraph_name  \\\n",
       "0           2549.1.1             Abstract   \n",
       "1           2549.2.1         Introduction   \n",
       "2           2549.2.2         Introduction   \n",
       "3           2549.2.3         Introduction   \n",
       "4           2549.2.4         Introduction   \n",
       "...              ...                  ...   \n",
       "132703   101131.17.2    C REPRODUCIBILITY   \n",
       "132711    101144.2.6      1. Introduction   \n",
       "132712    101144.2.7      1. Introduction   \n",
       "132713    101144.2.8      1. Introduction   \n",
       "132742    101144.7.1  6. Acknowledgements   \n",
       "\n",
       "                                          text_subsection label_subsection  \\\n",
       "0       work machin learn extract focus distinct subpr...             N_PD   \n",
       "1       extract problem convert text newswir articl we...             N_PD   \n",
       "2       increas import brought attent kind automat doc...             N_PD   \n",
       "3       work focus learn approach requir linguist expl...             N_PD   \n",
       "4       time work integr led need special wrapper proc...             N_PD   \n",
       "...                                                   ...              ...   \n",
       "132703  review confer paper iclr main task network rew...             N_PD   \n",
       "132711  approach preserv spatial spectral tempor struc...               PD   \n",
       "132712  increas effort automat detect phase start time...               PD   \n",
       "132713  sampl data descript data numer eeg read partic...               PD   \n",
       "132742  thank auton lab professor artur dubrawski prov...               PD   \n",
       "\n",
       "        label_id  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "...          ...  \n",
       "132703         0  \n",
       "132711         1  \n",
       "132712         1  \n",
       "132713         1  \n",
       "132742         1  \n",
       "\n",
       "[96380 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y.replace({'PD': 0, 'N_PD': 1}, inplace=True)\n",
    "#df.dtypes\n",
    "df['label_id'] = df['label_subsection'].factorize()[0]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'N_PD': 0, 'PD': 1} {0: 'N_PD', 1: 'PD'}\n"
     ]
    }
   ],
   "source": [
    "label_df = df[['label_subsection', 'label_id']].drop_duplicates().sort_values('label_id')\n",
    "label_dict = dict(label_df.values)\n",
    "label_id_dict = dict(label_df[['label_id', 'label_subsection']].values)\n",
    "print(label_dict, label_id_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Extracion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "corpus = df['text_subsection']\n",
    "\n",
    "vectorizer_modes = ['tdidf_bigr']#, 'tdidf', 'count_bigr', 'count']\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "vectorizers = {\n",
    "    'tdidf_bigr': {'name': 'TF-IDF_bigrams',\n",
    "                   'vect': TfidfVectorizer(max_features=40000, min_df=3, norm='l2', ngram_range=(1, 2))\n",
    "    },\n",
    "    'tdidf': {'name': 'TF-IDF',\n",
    "              'vect': TfidfVectorizer(max_features=40000, norm='l2')\n",
    "    },\n",
    "    'count_bigr': {'name': 'Count_bigrams',\n",
    "              'vect': CountVectorizer(max_features=40000, min_df=3, max_df=0.7, ngram_range=(1, 2))\n",
    "    },\n",
    "    'count': {'name': 'Count',\n",
    "              'vect': CountVectorizer(max_features=40000)\n",
    "    }\n",
    "}\n",
    "\n",
    "for vect_mode in vectorizer_modes:\n",
    "    vectorizers[vect_mode]['vectorizer'] = vectorizers[vect_mode]['vect']\n",
    "    vectorizers[vect_mode]['features'] = vectorizers[vect_mode]['vectorizer'].fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model_modes = ['lr', 'svc', 'rf', 'mnb']\n",
    "models = {\n",
    "    'lr': {'name': 'Logistic Regression ',\n",
    "           'estimator': LogisticRegression()\n",
    "    },\n",
    "    'rf': {'name': 'Random Forest       ',\n",
    "           'estimator': RandomForestClassifier(n_estimators=250, criterion='gini', max_depth=None)\n",
    "    },\n",
    "    'svc': {'name': 'Linear SVC         ',\n",
    "           'estimator': LinearSVC()\n",
    "    },\n",
    "    'mnb': {'name': 'Multinomial NB     ',\n",
    "           'estimator': MultinomialNB()\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computation of 'Logistic Regression' classifier with 'tdidf_bigr':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save vectorizer:\n",
    "#vectorizer_path = \"./resources/tdidf_bigram.pkl\"\n",
    "#with open(vectorizer_path, 'wb') as picklefile:\n",
    "#    pickle.dump(vectorizers['tdidf_bigr'], picklefile)\n",
    "\n",
    "## save vectorizer:\n",
    "#vectorizer_path = \"./resources/tdidf_bigram_vectorizer.pkl\"\n",
    "#with open(vectorizer_path, 'wb') as picklefile:\n",
    "#    pickle.dump(vectorizers['tdidf_bigr']['vectorizer'], picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96380, 40000) (96380,)\n"
     ]
    }
   ],
   "source": [
    "X_train = vectorizers['tdidf_bigr']['features']\n",
    "y_train = df['label_id']\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 12s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "classifier = models['mnb']['estimator']\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save it:\n",
    "classifier_path = \"./resources/tdidf_bigr-mnb.pkl\"\n",
    "with open(classifier_path, 'wb') as picklefile:\n",
    "    pickle.dump(classifier, picklefile, protocol=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
