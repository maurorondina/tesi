{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "#from importlib import reload\n",
    "#reload(logging)\n",
    "logging.basicConfig(level=logging.INFO, filename=\"predictSubjects_interesting_2.log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load paper-text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 601 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100036</td>\n",
       "      <td>paper present multimod biometr system fingerpr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100075</td>\n",
       "      <td>random trial known ab test select polici contr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100147</td>\n",
       "      <td>deep qnetwork returnbas reinforc learn promis ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100161</td>\n",
       "      <td>studi problem learn polici demonstr combinator...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100208</td>\n",
       "      <td>present novel method compress deep convolut ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21797</th>\n",
       "      <td>99842</td>\n",
       "      <td>case combin classifi show product rule aris ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21798</th>\n",
       "      <td>99920</td>\n",
       "      <td>propos novel dialogu model framework use binar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21799</th>\n",
       "      <td>99922</td>\n",
       "      <td>studi classif problem featur acquir cost goal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21800</th>\n",
       "      <td>99932</td>\n",
       "      <td>challeng imag process task describ illpos line...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21801</th>\n",
       "      <td>99988</td>\n",
       "      <td>model physic system learn molecular fingerprin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21802 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      paper_id                                               text\n",
       "0       100036  paper present multimod biometr system fingerpr...\n",
       "1       100075  random trial known ab test select polici contr...\n",
       "2       100147  deep qnetwork returnbas reinforc learn promis ...\n",
       "3       100161  studi problem learn polici demonstr combinator...\n",
       "4       100208  present novel method compress deep convolut ne...\n",
       "...        ...                                                ...\n",
       "21797    99842  case combin classifi show product rule aris ma...\n",
       "21798    99920  propos novel dialogu model framework use binar...\n",
       "21799    99922  studi classif problem featur acquir cost goal ...\n",
       "21800    99932  challeng imag process task describ illpos line...\n",
       "21801    99988  model physic system learn molecular fingerprin...\n",
       "\n",
       "[21802 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "dataset_path = \"../resources/interesting_arxiv_papers_textclean.pkl\"\n",
    "df_text = pd.read_pickle(dataset_path)\n",
    "df_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply more text_cleaning\n",
    "def initial_text_cleaning(text):\n",
    "    #text = text.lower()                                             # transform to lowercase\n",
    "    #text = re.sub(r'\\n', '', text)                                  # remove \\n\n",
    "    #text = re.sub(r'(\\(|\\[|\\{)[^(\\)|\\]|\\})]*(\\)|\\]|\\})', '', text)  # remove everything in parentheses\n",
    "    #text = re.sub(r'http(s)?:\\/\\/\\S+', '', text)                    # remove url\n",
    "    #text = re.sub(r'[^a-z\\s]', '', text)  #[^\\w\\s]                  # remove everything that is not a word (therefore also numbers and punctuation)\n",
    "    text = re.sub(r'\\b\\w{1,2}\\b', '', text)                         # remove all single and double letters\n",
    "    text = re.sub(r'\\b(h|i|j|k|x|y)+\\b', '', text)                  # remove some common letters used in formules \n",
    "    text = re.sub(r'\\s{2,}', ' ', text).strip()                     # reformat spaces\n",
    "    return text\n",
    "\n",
    "# text - cleaning:\n",
    "df_text['text'] = df_text['text'].apply(initial_text_cleaning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#\n",
    "#corpus = df['text']\n",
    "#tfidf_vect = TfidfVectorizer(max_features=40000, min_df=3, norm='l2', ngram_range=(1, 2))\n",
    "#features = tfidf_vect.fit_transform(corpus).toarray()\n",
    "#print(len(tfidf_vect.vocabulary_), features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save vectorizer:\n",
    "#vectorizer_path = \"../resources/tdidf_bigram_interesting_vectorizer.pkl\"\n",
    "#with open(vectorizer_path, 'wb') as picklefile:\n",
    "#    pickle.dump(tfidf_vect, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open vectorizer:\n",
    "tfidf_vect = None\n",
    "vectorizer_path = \"../resources/tdidf_bigram_interesting_vectorizer.pkl\"\n",
    "with open(vectorizer_path, 'rb') as picklefile:\n",
    "    tfidf_vect = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split in train and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>astro-ph</th>\n",
       "      <th>astro-ph.CO</th>\n",
       "      <th>astro-ph.EP</th>\n",
       "      <th>astro-ph.GA</th>\n",
       "      <th>astro-ph.HE</th>\n",
       "      <th>astro-ph.IM</th>\n",
       "      <th>astro-ph.SR</th>\n",
       "      <th>cond-mat</th>\n",
       "      <th>cond-mat.dis-nn</th>\n",
       "      <th>...</th>\n",
       "      <th>q-fin.RM</th>\n",
       "      <th>q-fin.ST</th>\n",
       "      <th>q-fin.TR</th>\n",
       "      <th>quant-ph</th>\n",
       "      <th>stat.AP</th>\n",
       "      <th>stat.CO</th>\n",
       "      <th>stat.ME</th>\n",
       "      <th>stat.ML</th>\n",
       "      <th>stat.OT</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41513</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>investig experienti learn paradigm acquir inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61821</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>work establish empir success framework adapt l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61822</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>paper present oimplement tsne embed techniqu c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61823</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>nonneg matrix factor ubiquit tool data analysi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61824</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>paper describ serial parallel composit model m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21797</th>\n",
       "      <td>101218</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>stateoftheart perform deep learn algorithm led...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21798</th>\n",
       "      <td>101219</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>mixup propos dataaugment scheme linearli inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21799</th>\n",
       "      <td>101220</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>linear discrimin analysi wellknown method dime...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21800</th>\n",
       "      <td>101222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>research investig techniqu data learn bayesian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21801</th>\n",
       "      <td>101223</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>aggreg set demonstr effect approach predict me...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21802 rows × 135 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      paper_id  astro-ph  astro-ph.CO  astro-ph.EP  astro-ph.GA  astro-ph.HE  \\\n",
       "0        41513         0            0            0            0            0   \n",
       "1        61821         0            0            0            0            0   \n",
       "2        61822         0            0            0            0            0   \n",
       "3        61823         0            0            0            0            0   \n",
       "4        61824         0            0            0            0            0   \n",
       "...        ...       ...          ...          ...          ...          ...   \n",
       "21797   101218         0            0            0            0            0   \n",
       "21798   101219         0            0            0            0            0   \n",
       "21799   101220         0            0            0            0            0   \n",
       "21800   101222         0            0            0            0            0   \n",
       "21801   101223         0            0            0            0            0   \n",
       "\n",
       "       astro-ph.IM  astro-ph.SR  cond-mat  cond-mat.dis-nn  ...  q-fin.RM  \\\n",
       "0                0            0         0                0  ...         0   \n",
       "1                0            0         0                0  ...         0   \n",
       "2                0            0         0                0  ...         0   \n",
       "3                0            0         0                0  ...         0   \n",
       "4                0            0         0                0  ...         0   \n",
       "...            ...          ...       ...              ...  ...       ...   \n",
       "21797            0            0         0                0  ...         0   \n",
       "21798            0            0         0                0  ...         0   \n",
       "21799            0            0         0                0  ...         0   \n",
       "21800            0            0         0                0  ...         0   \n",
       "21801            0            0         0                0  ...         0   \n",
       "\n",
       "       q-fin.ST  q-fin.TR  quant-ph  stat.AP  stat.CO  stat.ME  stat.ML  \\\n",
       "0             0         0         0        0        0        0        0   \n",
       "1             0         0         0        0        0        0        1   \n",
       "2             0         0         0        0        0        0        1   \n",
       "3             0         0         0        0        0        0        0   \n",
       "4             0         0         0        0        0        0        0   \n",
       "...         ...       ...       ...      ...      ...      ...      ...   \n",
       "21797         0         0         0        0        0        0        1   \n",
       "21798         0         0         0        0        0        0        1   \n",
       "21799         0         0         0        0        0        0        1   \n",
       "21800         0         0         0        0        0        0        1   \n",
       "21801         0         0         0        0        0        0        1   \n",
       "\n",
       "       stat.OT                                               text  \n",
       "0            0  investig experienti learn paradigm acquir inte...  \n",
       "1            0  work establish empir success framework adapt l...  \n",
       "2            0  paper present oimplement tsne embed techniqu c...  \n",
       "3            0  nonneg matrix factor ubiquit tool data analysi...  \n",
       "4            0  paper describ serial parallel composit model m...  \n",
       "...        ...                                                ...  \n",
       "21797        0  stateoftheart perform deep learn algorithm led...  \n",
       "21798        0  mixup propos dataaugment scheme linearli inter...  \n",
       "21799        0  linear discrimin analysi wellknown method dime...  \n",
       "21800        0  research investig techniqu data learn bayesian...  \n",
       "21801        0  aggreg set demonstr effect approach predict me...  \n",
       "\n",
       "[21802 rows x 135 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = \"../resources/papers-subjects-dataset.pkl\"\n",
    "df = pd.read_pickle(dataset_path)\n",
    "ids = list(df_text.paper_id)\n",
    "df = df.loc[df.paper_id.isin(ids)]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df = df.merge(df_text, how='left', on=\"paper_id\")\n",
    "df = df.drop(columns='primary-subject', axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "astro-ph.HE : 0\n",
      "cond-mat.quant-gas : 0\n",
      "cond-mat.soft : 0\n",
      "cond-mat.str-el : 0\n",
      "math.CT : 0\n",
      "math.GM : 0\n",
      "math.GN : 0\n",
      "math.RT : 0\n",
      "math.SP : 0\n",
      "nlin.CG : 0\n",
      "nlin.PS : 0\n",
      "nucl-ex : 0\n"
     ]
    }
   ],
   "source": [
    "subjects = list(df.columns)[2:-1]\n",
    "subjects_to_remove = []\n",
    "for s in subjects:\n",
    "    count_papers = df[s].sum()\n",
    "    if count_papers == 0:\n",
    "        print(s, ':', count_papers)\n",
    "        subjects_to_remove.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>astro-ph</th>\n",
       "      <th>astro-ph.CO</th>\n",
       "      <th>astro-ph.EP</th>\n",
       "      <th>astro-ph.GA</th>\n",
       "      <th>astro-ph.IM</th>\n",
       "      <th>astro-ph.SR</th>\n",
       "      <th>cond-mat</th>\n",
       "      <th>cond-mat.dis-nn</th>\n",
       "      <th>cond-mat.mes-hall</th>\n",
       "      <th>...</th>\n",
       "      <th>q-fin.RM</th>\n",
       "      <th>q-fin.ST</th>\n",
       "      <th>q-fin.TR</th>\n",
       "      <th>quant-ph</th>\n",
       "      <th>stat.AP</th>\n",
       "      <th>stat.CO</th>\n",
       "      <th>stat.ME</th>\n",
       "      <th>stat.ML</th>\n",
       "      <th>stat.OT</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41513</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>investig experienti learn paradigm acquir inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61821</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>work establish empir success framework adapt l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  paper_id  astro-ph  astro-ph.CO  astro-ph.EP  astro-ph.GA  astro-ph.IM  \\\n",
       "0    41513         0            0            0            0            0   \n",
       "1    61821         0            0            0            0            0   \n",
       "\n",
       "   astro-ph.SR  cond-mat  cond-mat.dis-nn  cond-mat.mes-hall  ...  q-fin.RM  \\\n",
       "0            0         0                0                  0  ...         0   \n",
       "1            0         0                0                  0  ...         0   \n",
       "\n",
       "   q-fin.ST  q-fin.TR  quant-ph  stat.AP  stat.CO  stat.ME  stat.ML  stat.OT  \\\n",
       "0         0         0         0        0        0        0        0        0   \n",
       "1         0         0         0        0        0        0        1        0   \n",
       "\n",
       "                                                text  \n",
       "0  investig experienti learn paradigm acquir inte...  \n",
       "1  work establish empir success framework adapt l...  \n",
       "\n",
       "[2 rows x 123 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=subjects_to_remove, axis=1)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17442 4360\n"
     ]
    }
   ],
   "source": [
    "X_df = df.loc[:, ['paper_id','text']]\n",
    "y_df = df.drop(columns=['paper_id','text'], axis=1)\n",
    "\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "\n",
    "msss = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=0.2, train_size=None, random_state=0)\n",
    "train_index, test_index = next(msss.split(X_df, y_df))\n",
    "print(len(train_index), len(test_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17442, 40000) (4360, 40000)\n"
     ]
    }
   ],
   "source": [
    "df_train = df.iloc[train_index]\n",
    "df_test = df.iloc[test_index]\n",
    "\n",
    "X_train = tfidf_vect.transform(df.iloc[train_index]['text'])\n",
    "X_test = tfidf_vect.transform(df_test['text'])\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17442, 121) (4360, 121)\n"
     ]
    }
   ],
   "source": [
    "y_train = y_df.iloc[train_index]\n",
    "y_test = y_df.iloc[test_index]\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "subjects = []\n",
    "for l,s in enumerate(list(y_train.columns)):\n",
    "    labels.append(l)\n",
    "    subjects.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 39.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix #, multilabel_confusion_matrix\n",
    "\n",
    "#model_modes = ['mnb', 'svc', 'lr', 'dummy_rnd', 'dummy_mf', 'dummy_stf']\n",
    "model_modes = ['cnb', 'cnb_norm']\n",
    "models = {\n",
    "    'lr': {'name': 'Logistic Regression',\n",
    "           'estimator': LogisticRegression(solver='sag', class_weight='balanced')\n",
    "    },\n",
    "    'svc': {'name': 'Linear SVC         ',\n",
    "            'estimator': LinearSVC(class_weight='balanced')\n",
    "    },\n",
    "    'mnb': {'name': 'Multinomial NB     ',\n",
    "            'estimator': MultinomialNB(fit_prior=True, class_prior=None)\n",
    "    },\n",
    "    'cnb': {'name': 'Complement NB      ',\n",
    "            'estimator': ComplementNB(fit_prior=True, class_prior=None, norm=False)\n",
    "    },\n",
    "    'cnb_norm': {'name': 'Complement NB norm ',\n",
    "                 'estimator': ComplementNB(fit_prior=True, class_prior=None, norm=True)\n",
    "    },\n",
    "    'dummy_rnd': {'name': 'Dummy Uniform      ',\n",
    "                  'estimator': DummyClassifier(strategy='uniform')\n",
    "    },\n",
    "    'dummy_mf': {'name': 'Dummy Most-Frequent',\n",
    "                 'estimator': DummyClassifier(strategy='most_frequent')\n",
    "    },\n",
    "    'dummy_stf': {'name': 'Dummy Stratified   ',\n",
    "                 'estimator': DummyClassifier(strategy='stratified')\n",
    "    }\n",
    "}\n",
    "\n",
    "logging.info(\"\\n\\n>>> TAXONOMY WITH %s SUBJECTS\\n\\n\" % len(subjects))\n",
    "\n",
    "for model_mode in model_modes:\n",
    "    logging.info(\"OneVsRest - %s\" % models[model_mode]['name'])\n",
    "    classifier = OneVsRestClassifier(models[model_mode]['estimator'], n_jobs=-1)\n",
    "    # TRAIN\n",
    "    logging.info(\"... training on %s samples\" % X_train.shape[0])\n",
    "    classifier.fit(X_train, y_train)\n",
    "    logging.info(\"... predicting on train set\")\n",
    "    prediction_train = classifier.predict(X_train)\n",
    "    logging.info(\"\\n\\t\\t accuracy = %s\" % accuracy_score(y_train, prediction_train))\n",
    "    logging.info(\"\\n\\t\\t f1_macro = %s\" % f1_score(y_train, prediction_train, average=\"macro\"))\n",
    "    logging.info(\"\\n%s\" % classification_report(y_train, prediction_train, labels=labels, target_names=subjects))\n",
    "    # TEST\n",
    "    logging.info(\"... predicting on test set\")\n",
    "    prediction_test = classifier.predict(X_test)\n",
    "    logging.info(\"\\n\\t\\t accuracy = %s\" % accuracy_score(y_test, prediction_test))\n",
    "    logging.info(\"\\n\\t\\t f1_macro = %s\" % f1_score(y_test, prediction_test, average=\"macro\"))\n",
    "    logging.info(\"\\n%s\" % classification_report(y_test, prediction_test, labels=labels, target_names=subjects))\n",
    "    logging.info(\"=\"*60)\n",
    "    \n",
    "    ## compare prediction_train-train ; compare prediction_test-test\n",
    "    #y_ntrain=y_train.to_numpy()\n",
    "    #y_ntest=y_test.to_numpy()\n",
    "    #subjects = list(y_train.columns)\n",
    "    #for i,subject in enumerate(subjects):\n",
    "    #    logger.debug(\"\\nsubject '%s':\" % subject)\n",
    "    #    logger.debug(\"- train:\")\n",
    "    #    logger.debug(confusion_matrix(y_ntrain[:,i],prediction_train[:,i]))\n",
    "    #    logger.debug(\"accuracy = %s\" % accuracy_score(y_ntrain[:,i],prediction_train[:,i]), ';\\t',\n",
    "    #                 \"f1_macro = %s\" % f1_score(y_ntrain[:,i],prediction_train[:,i], average=\"macro\"))\n",
    "    #    logger.debug(\"precision_macro = %s\" % precision_score(y_ntrain[:,i],prediction_train[:,i], average=\"macro\"), ';\\t',\n",
    "    #                 \"recall_macro = %s\" % recall_score(y_ntrain[:,i],prediction_train[:,i], average=\"macro\"))\n",
    "    #    logger.debug(\"- test:\")\n",
    "    #    logger.debug(confusion_matrix(y_ntest[:,i],prediction_test[:,i]))\n",
    "    #    logger.debug(\"accuracy = %s\" % accuracy_score(y_ntest[:,i],prediction_test[:,i]), ';\\t',\n",
    "    #                 \"f1_macro = %s\" % f1_score(y_ntest[:,i],prediction_test[:,i], average=\"macro\"))\n",
    "    #    logger.debug(\"precision_macro = %s\" % precision_score(y_ntest[:,i],prediction_test[:,i], average=\"macro\"), ';\\t',\n",
    "    #                 \"recall_macro = %s\" % recall_score(y_ntest[:,i],prediction_test[:,i], average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New attempt with a simplified taxonomy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>astro-ph</th>\n",
       "      <th>cond-mat</th>\n",
       "      <th>gr-qc</th>\n",
       "      <th>math-ph</th>\n",
       "      <th>nlin</th>\n",
       "      <th>physics</th>\n",
       "      <th>quant-ph</th>\n",
       "      <th>math</th>\n",
       "      <th>cs.AI</th>\n",
       "      <th>...</th>\n",
       "      <th>cs.SC</th>\n",
       "      <th>cs.SY</th>\n",
       "      <th>q-bio</th>\n",
       "      <th>q-fin</th>\n",
       "      <th>stat.ML</th>\n",
       "      <th>stat</th>\n",
       "      <th>eess</th>\n",
       "      <th>econ</th>\n",
       "      <th>hep</th>\n",
       "      <th>nucl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41513</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61821</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61822</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61823</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61824</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21797</th>\n",
       "      <td>101218</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21798</th>\n",
       "      <td>101219</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21799</th>\n",
       "      <td>101220</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21800</th>\n",
       "      <td>101222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21801</th>\n",
       "      <td>101223</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21802 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      paper_id  astro-ph  cond-mat  gr-qc  math-ph  nlin  physics  quant-ph  \\\n",
       "0        41513         0         0      0        0     0        0         0   \n",
       "1        61821         0         0      0        0     0        0         0   \n",
       "2        61822         0         0      0        0     0        0         0   \n",
       "3        61823         0         0      0        0     0        0         0   \n",
       "4        61824         0         0      0        0     0        0         0   \n",
       "...        ...       ...       ...    ...      ...   ...      ...       ...   \n",
       "21797   101218         0         0      0        0     0        0         0   \n",
       "21798   101219         0         0      0        0     0        0         0   \n",
       "21799   101220         0         0      0        0     0        0         0   \n",
       "21800   101222         0         0      0        0     0        0         0   \n",
       "21801   101223         0         0      0        0     0        0         0   \n",
       "\n",
       "       math  cs.AI  ...  cs.SC  cs.SY  q-bio  q-fin  stat.ML  stat  eess  \\\n",
       "0         0      1  ...      0      0      0      0        0     0     0   \n",
       "1         0      1  ...      0      0      0      0        1     0     0   \n",
       "2         0      0  ...      0      0      0      0        1     0     0   \n",
       "3         1      0  ...      0      0      0      0        0     0     0   \n",
       "4         0      0  ...      0      0      0      0        0     0     0   \n",
       "...     ...    ...  ...    ...    ...    ...    ...      ...   ...   ...   \n",
       "21797     0      0  ...      0      0      0      0        1     0     0   \n",
       "21798     0      1  ...      0      0      0      0        1     0     0   \n",
       "21799     0      0  ...      0      0      0      0        1     0     0   \n",
       "21800     0      1  ...      0      0      0      0        1     0     0   \n",
       "21801     0      1  ...      0      0      0      0        1     0     0   \n",
       "\n",
       "       econ  hep  nucl  \n",
       "0         0    0     0  \n",
       "1         0    0     0  \n",
       "2         0    0     0  \n",
       "3         0    0     0  \n",
       "4         0    0     0  \n",
       "...     ...  ...   ...  \n",
       "21797     0    0     0  \n",
       "21798     0    0     0  \n",
       "21799     0    0     0  \n",
       "21800     0    0     0  \n",
       "21801     0    0     0  \n",
       "\n",
       "[21802 rows x 57 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = \"../resources/papers-subjects-dataset-56.pkl\"\n",
    "df_56 = pd.read_pickle(dataset_path)\n",
    "df_56 = df_56.loc[df_56['paper_id'].isin(list(df['paper_id']))]\n",
    "df_56.reset_index(drop=True, inplace=True)\n",
    "df_56"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split in train and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17442, 40000) (4360, 40000)\n"
     ]
    }
   ],
   "source": [
    "#df_train = df.iloc[train_index]\n",
    "#df_test = df.iloc[test_index]\n",
    "#\n",
    "#X_train = tfidf_vect.transform(df.iloc[train_index]['text'])\n",
    "#X_test = tfidf_vect.transform(df_test['text'])\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17442, 56) (4360, 56)\n"
     ]
    }
   ],
   "source": [
    "y_df = df_56.drop(columns=['paper_id'], axis=1)\n",
    "y_train = y_df.iloc[train_index]\n",
    "y_test = y_df.iloc[test_index]\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "subjects = []\n",
    "for l,s in enumerate(list(y_train.columns)):\n",
    "    labels.append(l)\n",
    "    subjects.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"\\n\\n>>> TAXONOMY WITH %s SUBJECTS\\n\\n\" % len(subjects))\n",
    "\n",
    "for model_mode in model_modes:\n",
    "    logging.info(\"OneVsRest - %s\" % models[model_mode]['name'])\n",
    "    classifier = OneVsRestClassifier(models[model_mode]['estimator'], n_jobs=-1)\n",
    "    # TRAIN\n",
    "    logging.info(\"... training on %s samples\" % X_train.shape[0])\n",
    "    classifier.fit(X_train, y_train)\n",
    "    logging.info(\"... predicting on train set\")\n",
    "    prediction_train = classifier.predict(X_train)\n",
    "    logging.info(\"\\n\\t\\t accuracy = %s\" % accuracy_score(y_train, prediction_train))\n",
    "    logging.info(\"\\n\\t\\t f1_macro = %s\" % f1_score(y_train, prediction_train, average=\"macro\"))\n",
    "    logging.info(\"\\n%s\" % classification_report(y_train, prediction_train, labels=labels, target_names=subjects))\n",
    "    # TEST\n",
    "    logging.info(\"... predicting on test set\")\n",
    "    prediction_test = classifier.predict(X_test)\n",
    "    logging.info(\"\\n\\t\\t accuracy = %s\" % accuracy_score(y_test, prediction_test))\n",
    "    logging.info(\"\\n\\t\\t f1_macro = %s\" % f1_score(y_test, prediction_test, average=\"macro\"))\n",
    "    logging.info(\"\\n%s\" % classification_report(y_test, prediction_test, labels=labels, target_names=subjects))\n",
    "    logging.info(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
