{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import snappy\n",
    "import fastparquet\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "#from importlib import reload\n",
    "#reload(logging)\n",
    "logging.basicConfig(level=logging.INFO, filename=\"predictSubjects_2.log\")\n",
    "logger = logging.getLogger('distributed.worker')\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>inproc://192.168.1.4/16388/1</li>\n",
       "  <li><b>Dashboard: </b><a href='http://192.168.1.4:54283/status' target='_blank'>http://192.168.1.4:54283/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>6.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'inproc://192.168.1.4/16388/1' processes=1 threads=4, memory=6.00 GB>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client(n_workers=1, threads_per_worker=4, processes=False, memory_limit='6GB')\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load paper-text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.05 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41513</td>\n",
       "      <td>learn poke poke experienti learn intuit physic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41587</td>\n",
       "      <td>sampl complex episod fixedhorizon reinforc lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61821</td>\n",
       "      <td>adapt learn rate parallel stochast spars nonsm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61822</td>\n",
       "      <td>barneshutsn lauren der maaten pattern recognit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61823</td>\n",
       "      <td>block coordin descent spars nmf vamsi potluru ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363</th>\n",
       "      <td>101219</td>\n",
       "      <td>nov mixup local linear outofmanifold regular h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>101220</td>\n",
       "      <td>latent fisher discrimin analysi gang chen depa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365</th>\n",
       "      <td>101221</td>\n",
       "      <td>stochast graphlet embed anjan dutta member iee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1366</th>\n",
       "      <td>101222</td>\n",
       "      <td>bayesian approach learn bayesian network local...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>101223</td>\n",
       "      <td>codevec learn distribut represent code uri alo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37368 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     paper_id                                               text\n",
       "0       41513  learn poke poke experienti learn intuit physic...\n",
       "1       41587  sampl complex episod fixedhorizon reinforc lea...\n",
       "2       61821  adapt learn rate parallel stochast spars nonsm...\n",
       "3       61822  barneshutsn lauren der maaten pattern recognit...\n",
       "4       61823  block coordin descent spars nmf vamsi potluru ...\n",
       "...       ...                                                ...\n",
       "1363   101219  nov mixup local linear outofmanifold regular h...\n",
       "1364   101220  latent fisher discrimin analysi gang chen depa...\n",
       "1365   101221  stochast graphlet embed anjan dutta member iee...\n",
       "1366   101222  bayesian approach learn bayesian network local...\n",
       "1367   101223  codevec learn distribut represent code uri alo...\n",
       "\n",
       "[37368 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "parquets_dir = \"../resources/papers-textclean-parquets\"\n",
    "ddf = dd.read_parquet(parquets_dir, index=False, engine='fastparquet', columns=['paper_id', 'text'])\n",
    "ddf.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#\n",
    "#corpus = ddf['text'].compute()\n",
    "#tfidf_vect = TfidfVectorizer(max_features=40000, min_df=3, norm='l2', ngram_range=(1, 2))\n",
    "#features = tfidf_vect.fit_transform(corpus).toarray()\n",
    "#print(len(tfidf_vect.vocabulary_), features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save vectorizer:\n",
    "#vectorizer_path = \"../resources/tdidf_bigram_vectorizer.pkl\"\n",
    "#with open(vectorizer_path, 'wb') as picklefile:\n",
    "#    pickle.dump(tfidf_vect, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open vectorizer:\n",
    "tfidf_vect = None\n",
    "vectorizer_path = \"../resources/tdidf_bigram_vectorizer.pkl\"\n",
    "with open(vectorizer_path, 'rb') as picklefile:\n",
    "    tfidf_vect = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split in train and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29951 7417\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"../resources/papers-subjects-dataset.pkl\"\n",
    "df = pd.read_pickle(dataset_path)\n",
    "\n",
    "X_df = df.loc[:, 'paper_id':'primary-subject']\n",
    "y_df = df.drop(columns=['paper_id', 'primary-subject'], axis=1)\n",
    "\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "\n",
    "msss = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=0.2, train_size=None, random_state=0)\n",
    "train_index, test_index = next(msss.split(X_df, y_df))\n",
    "print(len(train_index), len(test_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29951, 40000) (7417, 40000)\n"
     ]
    }
   ],
   "source": [
    "ids_train = list(df.iloc[train_index]['paper_id'])\n",
    "ids_test = list(df.iloc[test_index]['paper_id'])\n",
    "\n",
    "ddf_train = ddf.loc[ddf['paper_id'].isin(ids_train)]\n",
    "ddf_test = ddf.loc[ddf['paper_id'].isin(ids_test)]\n",
    "\n",
    "X_train = tfidf_vect.transform(ddf_train['text'])\n",
    "X_test = tfidf_vect.transform(ddf_test['text'])\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29951, 133) (7417, 133)\n"
     ]
    }
   ],
   "source": [
    "y_train = y_df.iloc[train_index]\n",
    "y_test = y_df.iloc[test_index]\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "subjects = []\n",
    "for l,s in enumerate(list(y_train.columns)):\n",
    "    labels.append(l)\n",
    "    subjects.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix #, multilabel_confusion_matrix\n",
    "\n",
    "#model_modes = ['mnb', 'svc', 'lr', 'dummy_rnd', 'dummy_mf', 'dummy_stf']\n",
    "model_modes = ['cnb', 'cnb_norm']\n",
    "models = {\n",
    "    'lr': {'name': 'Logistic Regression',\n",
    "           'estimator': LogisticRegression(solver='sag', class_weight='balanced')\n",
    "    },\n",
    "    'svc': {'name': 'Linear SVC         ',\n",
    "            'estimator': LinearSVC(class_weight='balanced')\n",
    "    },\n",
    "    'mnb': {'name': 'Multinomial NB     ',\n",
    "            'estimator': MultinomialNB(fit_prior=True, class_prior=None)\n",
    "    },\n",
    "    'cnb': {'name': 'Complement NB      ',\n",
    "            'estimator': ComplementNB(fit_prior=True, class_prior=None, norm=False)\n",
    "    },\n",
    "    'cnb_norm': {'name': 'Complement NB norm ',\n",
    "                 'estimator': ComplementNB(fit_prior=True, class_prior=None, norm=True)\n",
    "    },\n",
    "    'dummy_rnd': {'name': 'Dummy Uniform      ',\n",
    "                  'estimator': DummyClassifier(strategy='uniform')\n",
    "    },\n",
    "    'dummy_mf': {'name': 'Dummy Most-Frequent',\n",
    "                 'estimator': DummyClassifier(strategy='most_frequent')\n",
    "    },\n",
    "    'dummy_stf': {'name': 'Dummy Stratified   ',\n",
    "                 'estimator': DummyClassifier(strategy='stratified')\n",
    "    }\n",
    "}\n",
    "\n",
    "logging.info(\"\\n\\n>>> TAXONOMY WITH %s SUBJECTS\\n\\n\" % len(subjects))\n",
    "\n",
    "for model_mode in model_modes:\n",
    "    logging.info(\"OneVsRest - %s\" % models[model_mode]['name'])\n",
    "    classifier = OneVsRestClassifier(models[model_mode]['estimator'], n_jobs=-1)\n",
    "    # TRAIN\n",
    "    logging.info(\"... training on %s samples\" % X_train.shape[0])\n",
    "    classifier.fit(X_train, y_train)\n",
    "    logging.info(\"... predicting on train set\")\n",
    "    prediction_train = classifier.predict(X_train)\n",
    "    logging.info(\"\\n\\t\\t accuracy = %s\" % accuracy_score(y_train, prediction_train))\n",
    "    logging.info(\"\\n\\t\\t f1_macro = %s\" % f1_score(y_train, prediction_train, average=\"macro\"))\n",
    "    logging.info(\"\\n%s\" % classification_report(y_train, prediction_train, labels=labels, target_names=subjects))\n",
    "    # TEST\n",
    "    logging.info(\"... predicting on test set\")\n",
    "    prediction_test = classifier.predict(X_test)\n",
    "    logging.info(\"\\n\\t\\t accuracy = %s\" % accuracy_score(y_test, prediction_test))\n",
    "    logging.info(\"\\n\\t\\t f1_macro = %s\" % f1_score(y_test, prediction_test, average=\"macro\"))\n",
    "    logging.info(\"\\n%s\" % classification_report(y_test, prediction_test, labels=labels, target_names=subjects))\n",
    "    logging.info(\"=\"*60)\n",
    "    \n",
    "    ## compare prediction_train-train ; compare prediction_test-test\n",
    "    #y_ntrain=y_train.to_numpy()\n",
    "    #y_ntest=y_test.to_numpy()\n",
    "    #subjects = list(y_train.columns)\n",
    "    #for i,subject in enumerate(subjects):\n",
    "    #    logger.debug(\"\\nsubject '%s':\" % subject)\n",
    "    #    logger.debug(\"- train:\")\n",
    "    #    logger.debug(confusion_matrix(y_ntrain[:,i],prediction_train[:,i]))\n",
    "    #    logger.debug(\"accuracy = %s\" % accuracy_score(y_ntrain[:,i],prediction_train[:,i]), ';\\t',\n",
    "    #                 \"f1_macro = %s\" % f1_score(y_ntrain[:,i],prediction_train[:,i], average=\"macro\"))\n",
    "    #    logger.debug(\"precision_macro = %s\" % precision_score(y_ntrain[:,i],prediction_train[:,i], average=\"macro\"), ';\\t',\n",
    "    #                 \"recall_macro = %s\" % recall_score(y_ntrain[:,i],prediction_train[:,i], average=\"macro\"))\n",
    "    #    logger.debug(\"- test:\")\n",
    "    #    logger.debug(confusion_matrix(y_ntest[:,i],prediction_test[:,i]))\n",
    "    #    logger.debug(\"accuracy = %s\" % accuracy_score(y_ntest[:,i],prediction_test[:,i]), ';\\t',\n",
    "    #                 \"f1_macro = %s\" % f1_score(y_ntest[:,i],prediction_test[:,i], average=\"macro\"))\n",
    "    #    logger.debug(\"precision_macro = %s\" % precision_score(y_ntest[:,i],prediction_test[:,i], average=\"macro\"), ';\\t',\n",
    "    #                 \"recall_macro = %s\" % recall_score(y_ntest[:,i],prediction_test[:,i], average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New attempt with a simplified taxonomy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>astro-ph</th>\n",
       "      <th>cond-mat</th>\n",
       "      <th>gr-qc</th>\n",
       "      <th>math-ph</th>\n",
       "      <th>nlin</th>\n",
       "      <th>physics</th>\n",
       "      <th>quant-ph</th>\n",
       "      <th>math</th>\n",
       "      <th>cs.AI</th>\n",
       "      <th>...</th>\n",
       "      <th>cs.SC</th>\n",
       "      <th>cs.SY</th>\n",
       "      <th>q-bio</th>\n",
       "      <th>q-fin</th>\n",
       "      <th>stat.ML</th>\n",
       "      <th>stat</th>\n",
       "      <th>eess</th>\n",
       "      <th>econ</th>\n",
       "      <th>hep</th>\n",
       "      <th>nucl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41513</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41587</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61821</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61822</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61823</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37363</th>\n",
       "      <td>101219</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37364</th>\n",
       "      <td>101220</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37365</th>\n",
       "      <td>101221</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37366</th>\n",
       "      <td>101222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37367</th>\n",
       "      <td>101223</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37368 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      paper_id  astro-ph  cond-mat  gr-qc  math-ph  nlin  physics  quant-ph  \\\n",
       "0        41513         0         0      0        0     0        0         0   \n",
       "1        41587         0         0      0        0     0        0         0   \n",
       "2        61821         0         0      0        0     0        0         0   \n",
       "3        61822         0         0      0        0     0        0         0   \n",
       "4        61823         0         0      0        0     0        0         0   \n",
       "...        ...       ...       ...    ...      ...   ...      ...       ...   \n",
       "37363   101219         0         0      0        0     0        0         0   \n",
       "37364   101220         0         0      0        0     0        0         0   \n",
       "37365   101221         0         0      0        0     0        0         0   \n",
       "37366   101222         0         0      0        0     0        0         0   \n",
       "37367   101223         0         0      0        0     0        0         0   \n",
       "\n",
       "       math  cs.AI  ...  cs.SC  cs.SY  q-bio  q-fin  stat.ML  stat  eess  \\\n",
       "0         0      1  ...      0      0      0      0        0     0     0   \n",
       "1         0      1  ...      0      0      0      0        1     0     0   \n",
       "2         0      1  ...      0      0      0      0        1     0     0   \n",
       "3         0      0  ...      0      0      0      0        1     0     0   \n",
       "4         1      0  ...      0      0      0      0        0     0     0   \n",
       "...     ...    ...  ...    ...    ...    ...    ...      ...   ...   ...   \n",
       "37363     0      1  ...      0      0      0      0        1     0     0   \n",
       "37364     0      0  ...      0      0      0      0        1     0     0   \n",
       "37365     0      0  ...      0      0      0      0        1     0     0   \n",
       "37366     0      1  ...      0      0      0      0        1     0     0   \n",
       "37367     0      1  ...      0      0      0      0        1     0     0   \n",
       "\n",
       "       econ  hep  nucl  \n",
       "0         0    0     0  \n",
       "1         0    0     0  \n",
       "2         0    0     0  \n",
       "3         0    0     0  \n",
       "4         0    0     0  \n",
       "...     ...  ...   ...  \n",
       "37363     0    0     0  \n",
       "37364     0    0     0  \n",
       "37365     0    0     0  \n",
       "37366     0    0     0  \n",
       "37367     0    0     0  \n",
       "\n",
       "[37368 rows x 57 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = \"../resources/papers-subjects-dataset-56.pkl\"\n",
    "df = pd.read_pickle(dataset_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split in train and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29951, 40000) (7417, 40000)\n"
     ]
    }
   ],
   "source": [
    "ids_train = list(df.iloc[train_index]['paper_id'])\n",
    "ids_test = list(df.iloc[test_index]['paper_id'])\n",
    "\n",
    "ddf_train = ddf.loc[ddf['paper_id'].isin(ids_train)]\n",
    "ddf_test = ddf.loc[ddf['paper_id'].isin(ids_test)]\n",
    "\n",
    "X_train = tfidf_vect.transform(ddf_train['text'])\n",
    "X_test = tfidf_vect.transform(ddf_test['text'])\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29951, 56) (7417, 56)\n"
     ]
    }
   ],
   "source": [
    "y_df = df.drop(columns=['paper_id'], axis=1)\n",
    "y_train = y_df.iloc[train_index]\n",
    "y_test = y_df.iloc[test_index]\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "subjects = []\n",
    "for l,s in enumerate(list(y_train.columns)):\n",
    "    labels.append(l)\n",
    "    subjects.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"\\n\\n>>> TAXONOMY WITH %s SUBJECTS\\n\\n\" % len(subjects))\n",
    "\n",
    "for model_mode in model_modes:\n",
    "    logging.info(\"OneVsRest - %s\" % models[model_mode]['name'])\n",
    "    classifier = OneVsRestClassifier(models[model_mode]['estimator'], n_jobs=-1)\n",
    "    # TRAIN\n",
    "    logging.info(\"... training on %s samples\" % X_train.shape[0])\n",
    "    classifier.fit(X_train, y_train)\n",
    "    logging.info(\"... predicting on train set\")\n",
    "    prediction_train = classifier.predict(X_train)\n",
    "    logging.info(\"\\n\\t\\t accuracy = %s\" % accuracy_score(y_train, prediction_train))\n",
    "    logging.info(\"\\n\\t\\t f1_macro = %s\" % f1_score(y_train, prediction_train, average=\"macro\"))\n",
    "    logging.info(\"\\n%s\" % classification_report(y_train, prediction_train, labels=labels, target_names=subjects))\n",
    "    # TEST\n",
    "    logging.info(\"... predicting on test set\")\n",
    "    prediction_test = classifier.predict(X_test)\n",
    "    logging.info(\"\\n\\t\\t accuracy = %s\" % accuracy_score(y_test, prediction_test))\n",
    "    logging.info(\"\\n\\t\\t f1_macro = %s\" % f1_score(y_test, prediction_test, average=\"macro\"))\n",
    "    logging.info(\"\\n%s\" % classification_report(y_test, prediction_test, labels=labels, target_names=subjects))\n",
    "    logging.info(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
